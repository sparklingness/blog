{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2020-04-19-BERT_Fine-Tuning-Sentence-Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSwL1qNy45BV",
        "colab_type": "text"
      },
      "source": [
        "# BERT Fine-Tuning Sentence Classification\n",
        "\n",
        "> BERT Fine-Tuning Tutorial with PyTorch\n",
        "> \n",
        "> ref: https://colab.research.google.com/drive/1Y4o3jh3ZH70tl6mCd76vz_IxX23biCPP\n",
        "\n",
        "- toc: true \n",
        "- badges: true\n",
        "- comments: true\n",
        "- categories: [bert, jupyter]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGJiXNeLGbTf",
        "colab_type": "text"
      },
      "source": [
        "# 1. Setup\n",
        "## 1.1. Using Colab GPU for Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cTDQfMOQcue",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "d5661c37-03a6-4bc5-cea6-d5406b7009c8"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w09zSc6ZIJoh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "71041200-19fc-4536-8e9c-0c2def96fea3"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available,\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    # Tell PyTorch to user the GPU.\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will user the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not,\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will user the GPU: Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5K0Jts-aJzf6",
        "colab_type": "text"
      },
      "source": [
        "## 1.2. Installing the Hugging Face Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gekFfEBMJntx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install transformers -q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXnZp-rPMEij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install wget -q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPJ8xxBJVATO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "7577f4da-17fc-405f-8ffd-25894c218ed3"
      },
      "source": [
        "import wget \n",
        "import os\n",
        "\n",
        "print('Downloading dataset...')\n",
        "\n",
        "# The URL for the dataset zip file.\n",
        "url = 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'\n",
        "\n",
        "# Download the file (if we haven't already)\n",
        "if not os.path.exists('./cola_public_1.1.zip'):\n",
        "    wget.download(url, './cola_public_1.1.zip')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading dataset...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kXl3tTuZb-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unzip the dataset (if we haven't already)\n",
        "if not os.path.exists('./cola_public/'):\n",
        "    ! unzip cola_public_1.1.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikX-y7RDZjKc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7d43eb80-78ef-42e2-b29b-d80668512305"
      },
      "source": [
        "! head cola_public/*/*"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> cola_public/raw/in_domain_dev.tsv <==\n",
            "gj04\t1\t\tThe sailors rode the breeze clear of the rocks.\n",
            "gj04\t1\t\tThe weights made the rope stretch over the pulley.\n",
            "gj04\t1\t\tThe mechanical doll wriggled itself loose.\n",
            "cj99\t1\t\tIf you had eaten more, you would want less.\n",
            "cj99\t0\t*\tAs you eat the most, you want the least.\n",
            "cj99\t0\t*\tThe more you would want, the less you would eat.\n",
            "cj99\t0\t*\tI demand that the more John eat, the more he pays.\n",
            "cj99\t1\t\tMary listens to the Grateful Dead, she gets depressed.\n",
            "cj99\t1\t\tThe angrier Mary got, the more she looked at pictures.\n",
            "cj99\t1\t\tThe higher the stakes, the lower his expectations are.\n",
            "\n",
            "==> cola_public/raw/in_domain_train.tsv <==\n",
            "gj04\t1\t\tOur friends won't buy this analysis, let alone the next one we propose.\n",
            "gj04\t1\t\tOne more pseudo generalization and I'm giving up.\n",
            "gj04\t1\t\tOne more pseudo generalization or I'm giving up.\n",
            "gj04\t1\t\tThe more we study verbs, the crazier they get.\n",
            "gj04\t1\t\tDay by day the facts are getting murkier.\n",
            "gj04\t1\t\tI'll fix you a drink.\n",
            "gj04\t1\t\tFred watered the plants flat.\n",
            "gj04\t1\t\tBill coughed his way out of the restaurant.\n",
            "gj04\t1\t\tWe're dancing the night away.\n",
            "gj04\t1\t\tHerman hammered the metal flat.\n",
            "\n",
            "==> cola_public/raw/out_of_domain_dev.tsv <==\n",
            "clc95\t1\t\tSomebody just left - guess who.\n",
            "clc95\t1\t\tThey claimed they had settled on something, but it wasn't clear what they had settled on.\n",
            "clc95\t1\t\tIf Sam was going, Sally would know where.\n",
            "clc95\t1\t\tThey're going to serve the guests something, but it's unclear what.\n",
            "clc95\t1\t\tShe's reading. I can't imagine what.\n",
            "clc95\t1\t\tJohn said Joan saw someone from her graduating class.\n",
            "clc95\t0\t*\tJohn ate dinner but I don't know who.\n",
            "clc95\t0\t*\tShe mailed John a letter, but I don't know to whom.\n",
            "clc95\t1\t\tI served leek soup to my guests.\n",
            "clc95\t1\t\tI served my guests.\n",
            "\n",
            "==> cola_public/tokenized/in_domain_dev.tsv <==\n",
            "gj04\t1\t\tthe sailors rode the breeze clear of the rocks .\n",
            "gj04\t1\t\tthe weights made the rope stretch over the pulley .\n",
            "gj04\t1\t\tthe mechanical doll wriggled itself loose .\n",
            "cj99\t1\t\tif you had eaten more , you would want less .\n",
            "cj99\t0\t*\tas you eat the most , you want the least .\n",
            "cj99\t0\t*\tthe more you would want , the less you would eat .\n",
            "cj99\t0\t*\ti demand that the more john eat , the more he pays .\n",
            "cj99\t1\t\tmary listens to the grateful dead , she gets depressed .\n",
            "cj99\t1\t\tthe angrier mary got , the more she looked at pictures .\n",
            "cj99\t1\t\tthe higher the stakes , the lower his expectations are .\n",
            "\n",
            "==> cola_public/tokenized/in_domain_train.tsv <==\n",
            "gj04\t1\t\tour friends wo n't buy this analysis , let alone the next one we propose .\n",
            "gj04\t1\t\tone more pseudo generalization and i 'm giving up .\n",
            "gj04\t1\t\tone more pseudo generalization or i 'm giving up .\n",
            "gj04\t1\t\tthe more we study verbs , the crazier they get .\n",
            "gj04\t1\t\tday by day the facts are getting murkier .\n",
            "gj04\t1\t\ti 'll fix you a drink .\n",
            "gj04\t1\t\tfred watered the plants flat .\n",
            "gj04\t1\t\tbill coughed his way out of the restaurant .\n",
            "gj04\t1\t\twe 're dancing the night away .\n",
            "gj04\t1\t\therman hammered the metal flat .\n",
            "\n",
            "==> cola_public/tokenized/out_of_domain_dev.tsv <==\n",
            "clc95\t1\t\tsomebody just left - guess who .\n",
            "clc95\t1\t\tthey claimed they had settled on something , but it was n't clear what they had settled on .\n",
            "clc95\t1\t\tif sam was going , sally would know where .\n",
            "clc95\t1\t\tthey 're going to serve the guests something , but it 's unclear what .\n",
            "clc95\t1\t\tshe 's reading . i ca n't imagine what .\n",
            "clc95\t1\t\tjohn said joan saw someone from her graduating class .\n",
            "clc95\t0\t*\tjohn ate dinner but i do n't know who .\n",
            "clc95\t0\t*\tshe mailed john a letter , but i do n't know to whom .\n",
            "clc95\t1\t\ti served leek soup to my guests .\n",
            "clc95\t1\t\ti served my guests .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlmzRCa8avwP",
        "colab_type": "text"
      },
      "source": [
        "## 2.2. Parse"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00B9-zxvaavw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "outputId": "e238d812-1f18-4dbe-f6fe-5ea0928f0e4a"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"./cola_public/raw/in_domain_train.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data\n",
        "df.sample(10)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 8,551\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_source</th>\n",
              "      <th>label</th>\n",
              "      <th>label_notes</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>r-67</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I want to peruse that contract before filing a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1670</th>\n",
              "      <td>r-67</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>This hat Tom said Al thought you wanted me to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6952</th>\n",
              "      <td>m_02</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Jane visits Emma.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>449</th>\n",
              "      <td>bc01</td>\n",
              "      <td>0</td>\n",
              "      <td>??</td>\n",
              "      <td>Who is he reading a book that criticizes?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4988</th>\n",
              "      <td>ks08</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The fact that scientists have now established ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1830</th>\n",
              "      <td>r-67</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>That informers they never use is claimed by th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6508</th>\n",
              "      <td>d_98</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>Every cat doesn't like mice, but Felix doesn't.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8329</th>\n",
              "      <td>ad03</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I asked did Medea poison Jason.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1358</th>\n",
              "      <td>r-67</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>They will give me a hat that I won't like whic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5503</th>\n",
              "      <td>b_73</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Her mother wants Mary to be such an eminent wo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     sentence_source  ...                                           sentence\n",
              "1337            r-67  ...  I want to peruse that contract before filing a...\n",
              "1670            r-67  ...  This hat Tom said Al thought you wanted me to ...\n",
              "6952            m_02  ...                                  Jane visits Emma.\n",
              "449             bc01  ...          Who is he reading a book that criticizes?\n",
              "4988            ks08  ...  The fact that scientists have now established ...\n",
              "1830            r-67  ...  That informers they never use is claimed by th...\n",
              "6508            d_98  ...    Every cat doesn't like mice, but Felix doesn't.\n",
              "8329            ad03  ...                    I asked did Medea poison Jason.\n",
              "1358            r-67  ...  They will give me a hat that I won't like whic...\n",
              "5503            b_73  ...  Her mother wants Mary to be such an eminent wo...\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4QQDXoOeG6k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "9dd2176e-7930-4d07-abc2-14a674b5ad19"
      },
      "source": [
        "df[df.label == 0].sample(5)[['sentence', 'label']]"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6544</th>\n",
              "      <td>The table, I put Kim on which supported the book.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5993</th>\n",
              "      <td>Has Calvin a bowl?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>379</th>\n",
              "      <td>How do you wonder who could solve this problem.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>588</th>\n",
              "      <td>the branch dropped bare of its apple.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7194</th>\n",
              "      <td>Your desk before, this girl in the red coat wi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentence  label\n",
              "6544  The table, I put Kim on which supported the book.      0\n",
              "5993                                 Has Calvin a bowl?      0\n",
              "379     How do you wonder who could solve this problem.      0\n",
              "588               the branch dropped bare of its apple.      0\n",
              "7194  Your desk before, this girl in the red coat wi...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcGqjTAeempG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqW5Ro9ufetA",
        "colab_type": "text"
      },
      "source": [
        "# 3. Tokenization & Input Formatting\n",
        "\n",
        "## 3.1. BERT Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wo-H7en6fPdW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "5d531447-594a-4249-d995-c52ec36f7356"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased', do_lower_case=True)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2t18cdogfSVA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "f19e9d4c-17ea-4275-a153-35070ffa9e50"
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Tokenized:  ['our', 'friends', 'won', \"'\", 't', 'buy', 'this', 'analysis', ',', 'let', 'alone', 'the', 'next', 'one', 'we', 'propose', '.']\n",
            "Token IDs:  [14008, 16119, 11441, 112, 162, 35172, 10372, 15559, 117, 12421, 19145, 10103, 12878, 10399, 11312, 25690, 119]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f7Ic24SjiYY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "c036ccd1-2c93-4e3c-b509-f633a066c680"
      },
      "source": [
        "korean = \"안녕하세요. 반갑습니다. 너는 이름이 뭐니? 오늘 날씨가 맑고 좋구나.\"\n",
        "# Print the original sentence.\n",
        "print(' Original: ', korean)\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(korean))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(korean)))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  안녕하세요. 반갑습니다. 너는 이름이 뭐니? 오늘 날씨가 맑고 좋구나.\n",
            "Tokenized:  ['ᄋ', '##ᅡᆫ', '##녀', '##ᆼ', '##하', '##세', '##요', '.', 'ᄇ', '##ᅡᆫ', '##가', '##ᆸ', '##스', '##ᆸ니다', '.', 'ᄂ', '##ᅥ', '##는', '이', '##름이', 'ᄆ', '##ᅯ', '##니', '?', 'ᄋ', '##ᅩ', '##ᄂ', '##ᅳᆯ', '날', '##씨', '##가', 'ᄆ', '##ᅡ', '##ᆰ', '##고', 'ᄌ', '##ᅩ', '##ᇂ', '##구', '##나', '.']\n",
            "Token IDs:  [1174, 26646, 49345, 13045, 35132, 25169, 47024, 119, 1170, 26646, 11376, 17360, 13212, 79427, 119, 1165, 33645, 11192, 12398, 89420, 1169, 97090, 25536, 136, 1174, 29347, 97071, 63277, 76818, 47928, 11376, 1169, 25539, 97098, 12300, 1175, 29347, 97109, 16336, 16801, 119]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWJvJRdslm_z",
        "colab_type": "text"
      },
      "source": [
        "When we actually convert all of our sentences, we'll use the `tokenize.encode` functio to handle both steps, rather than calling `tokenize` and `convert_tokens_to_ids` seperately."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFrTYbLCl-TD",
        "colab_type": "text"
      },
      "source": [
        "## 3.2. Required Formatting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQgBMd6YuhMF",
        "colab_type": "text"
      },
      "source": [
        "## 3.3. Tokenize Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poyJBjpBlJ5y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "6cb560b5-65a8-44c4-e320-ffa7378a9ca7"
      },
      "source": [
        "max_len = 0\n",
        "\n",
        "# For every sentence,\n",
        "for sent in sentences:\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "    # Update the maximum sentence langth.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max sentence length: ', max_len)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  48\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aehil_yUvm5Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "d0aa236a-fc39-419a-844b-99d243a529a8"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to their word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence,\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    # (1) Tokenize the sentence.\n",
        "    # (2) Prepend the `[CLS]` token to the start.\n",
        "    # (3) Append the `[SEP]` token to the end.\n",
        "    # (4) Map tokens to their IDs.\n",
        "    # (5) Pad or truncate the sentence to `max_length`\n",
        "    # (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "        sent,                                       # Sentence to encode.\n",
        "        add_special_tokens = True,      # Add '[CLS]' and '[SEP]'\n",
        "        max_length = 64,                           # Pad & truncate all sentences.\n",
        "        pad_to_max_length = True,\n",
        "        return_attention_mask = True,   # Construct attn. masks.\n",
        "        return_Tensors = 'pt',                  # Return pytorch tensors.\n",
        "    )\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "    # And its attention mask (simply differentiates padding from non-padding.)\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.FloatTensor(input_ids)\n",
        "attention_masks = torch.FloatTensor(attention_masks)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original:  ', sentences[0])\n",
        "print('Token IDs: ', input_ids[0])"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:   Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Token IDs:  tensor([  101., 14008., 16119., 11441.,   112.,   162., 35172., 10372., 15559.,\n",
            "          117., 12421., 19145., 10103., 12878., 10399., 11312., 25690.,   119.,\n",
            "          102.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
            "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
            "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
            "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
            "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
            "            0.])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNizyMqx3eeZ",
        "colab_type": "text"
      },
      "source": [
        "## 3.4. Training & Validation Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLaFck7azYyP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "241e7b1e-432d-4494-afad-9969cbc01872"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Devide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5} training samples'.format(train_size))\n",
        "print('{:>5} validation samples'.format(val_size))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 7695 training samples\n",
            "  856 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uI64ApIf16pR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order.\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,   # The training samples.\n",
        "    sampler = RandomSampler(train_dataset),   # Select batches randomly\n",
        "    batch_size = batch_size   # Trains with this batch size.\n",
        ")\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "    val_dataset,   # The validation samples.\n",
        "    sampler = SequentialSampler(val_dataset),   # Pull out batches sequentially.\n",
        "    batch_size = batch_size   # Evaluate with this batch size.\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfsIwCeM18zU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ov31_D2X196v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5NBqMhi2B1I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}