{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Inspect BERT Vocabulary.ipynb의 사본",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RIsxttyyvbw",
        "colab_type": "text"
      },
      "source": [
        "# Bert Notebook Blog Post(2)\n",
        "> A tutorial of BERT for Jupyter notebooks.\n",
        "\n",
        "- toc: true \n",
        "- badges: true\n",
        "- comments: true\n",
        "- categories: [bert, jupyter]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3k0IToe0a_7",
        "colab_type": "text"
      },
      "source": [
        "ref: http://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-I9rR2G-0jjW",
        "colab_type": "text"
      },
      "source": [
        "## 1. Loading Pre-Trained BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOJCjIYC0m1e",
        "colab_type": "code",
        "outputId": "47c91894-244d-4227-81c1-9c1c0e3bac35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        }
      },
      "source": [
        "! pip install pytorch-pretrained-bert"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-pretrained-bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 19.2MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.18.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.12.38)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.4.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.38.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.21.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.9.5)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.38 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.15.38)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.3.3)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.38->boto3->pytorch-pretrained-bert) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.38->boto3->pytorch-pretrained-bert) (0.15.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.16.0,>=1.15.38->boto3->pytorch-pretrained-bert) (1.12.0)\n",
            "Installing collected packages: pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqpPYLQo0qio",
        "colab_type": "code",
        "outputId": "07492a0a-1185-4237-8dfe-1bc644a950ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "import torch\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
        "\n",
        "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
        "import logging\n",
        "# logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "# Load pre-trained model tokenizer (vocabulary)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 315280.35B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBV8t3or0wz-",
        "colab_type": "text"
      },
      "source": [
        "## 2. Input Formatting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4m8uuS60xmb",
        "colab_type": "text"
      },
      "source": [
        "### 2.1. Special Tokens\n",
        "\n",
        "Special tokens to mark the beginning ([CLS]) and seprataion/end of sentences ([SEP])\n",
        "\n",
        "BERT can take as input either one or two sentences, and expects special tokens to mark the beginning and end of each one:\n",
        "\n",
        "**2 Sentence Input:**\n",
        "\n",
        "`[CLS] The man wnent to the store. [SEP] He bought a gallon of milk. [SEP]`\n",
        "\n",
        "**1 Sentence Input:**\n",
        "\n",
        "`[CLS] The man went to the store. [SEP]`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjTSDZOM05c2",
        "colab_type": "text"
      },
      "source": [
        "### 2.2. Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5WS1U_q04nh",
        "colab_type": "code",
        "outputId": "a83a0233-c4b2-4284-e426-73d32be08222",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "text = \"Here is the sentence I want embeddings for.\"\n",
        "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
        "\n",
        "# Tokenize our sentence with the BERT tokenizer.\n",
        "tokenized_text = tokenizer.tokenize(marked_text)\n",
        "\n",
        "# Print out the tokens.\n",
        "print(tokenized_text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'here', 'is', 'the', 'sentence', 'i', 'want', 'em', '##bed', '##ding', '##s', 'for', '.', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLwjipAg1Bmn",
        "colab_type": "code",
        "outputId": "2d5d348d-55ee-495a-8ba4-e892eb0ff660",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        }
      },
      "source": [
        "# Define a new example sentence with multiple meanings of the word \"bank\"\n",
        "text = \"After stealing money from the bank vault, the bank robber was seen fishing on the Mississippi river bank.\"\n",
        "\n",
        "# Add the special tokens.\n",
        "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
        "\n",
        "# Split the sentence into tokens.\n",
        "tokenized_text = tokenizer.tokenize(marked_text)\n",
        "\n",
        "# Map the token strings to their vocabulary indeces.\n",
        "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "\n",
        "# Display the words with their indeces.\n",
        "for tup in zip(tokenized_text, indexed_tokens):\n",
        "    print('{:<12} {:>6,}'.format(tup[0], tup[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS]           101\n",
            "after         2,044\n",
            "stealing     11,065\n",
            "money         2,769\n",
            "from          2,013\n",
            "the           1,996\n",
            "bank          2,924\n",
            "vault        11,632\n",
            ",             1,010\n",
            "the           1,996\n",
            "bank          2,924\n",
            "robber       27,307\n",
            "was           2,001\n",
            "seen          2,464\n",
            "fishing       5,645\n",
            "on            2,006\n",
            "the           1,996\n",
            "mississippi   5,900\n",
            "river         2,314\n",
            "bank          2,924\n",
            ".             1,012\n",
            "[SEP]           102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QA1KsJ8k1EWP",
        "colab_type": "text"
      },
      "source": [
        "### 2.3. Segment ID"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xV0hHOUJ1Gzp",
        "colab_type": "code",
        "outputId": "c8ff5184-152b-49a8-99c3-a58496d9cc43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "# Mark each of the 22 tokens as belonging to sentence \"1\".\n",
        "segments_ids = [1] * len(tokenized_text)\n",
        "\n",
        "print(segments_ids)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClUM32R51JP8",
        "colab_type": "text"
      },
      "source": [
        "## 3. Extracting Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "778_i1RH1J9B",
        "colab_type": "text"
      },
      "source": [
        "### 3.1. Running BERT on our text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cu3uLRHZ1NW4",
        "colab_type": "text"
      },
      "source": [
        "`model.eval()` evaluation mode turns off dropout regularization which is used in training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kz1X6bzy1MVs",
        "colab_type": "code",
        "outputId": "43315f7c-ceca-40cd-fe64-777aa4e3acc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Convert inputs to PyTorch tensors\n",
        "tokens_tensor = torch.tensor([indexed_tokens])\n",
        "print(tokens_tensor)\n",
        "segments_tensors = torch.tensor([segments_ids])\n",
        "\n",
        "# Load pre-trained model (weights)\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
        "model.eval()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[  101,  2044, 11065,  2769,  2013,  1996,  2924, 11632,  1010,  1996,\n",
            "          2924, 27307,  2001,  2464,  5645,  2006,  1996,  5900,  2314,  2924,\n",
            "          1012,   102]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 407873900/407873900 [00:35<00:00, 11382845.79B/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): BertLayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7w_hjVc1SHo",
        "colab_type": "text"
      },
      "source": [
        "`torch.no_grad` deactivates the gradient calculations, saves memory, and speeds up computation. (we don't need gradients or backpropagation since we're just running a forward pass)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRjXiYmK1XqQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict hidden states features for each layer\n",
        "with torch.no_grad():\n",
        "    encoded_layers, _ = model(tokens_tensor, segments_tensors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbE7hbNn1YyW",
        "colab_type": "text"
      },
      "source": [
        "### 3.2. Understanding the Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dqGxS681b96",
        "colab_type": "code",
        "outputId": "4264d00f-85e9-4960-b980-99b12330fec9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "print(\"Number of layers:\", len(encoded_layers))\n",
        "layer_i = 0\n",
        "\n",
        "print(\"Number of batches:\", len(encoded_layers[layer_i]))\n",
        "batch_i = 0\n",
        "\n",
        "print(\"Number of tokens:\", len(encoded_layers[layer_i][batch_i]))\n",
        "token_i = 0\n",
        "\n",
        "print(\"Number of hidden units:\", len(encoded_layers[layer_i][batch_i][token_i]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of layers: 12\n",
            "Number of batches: 1\n",
            "Number of tokens: 22\n",
            "Number of hidden units: 768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYvc2Tti1k0t",
        "colab_type": "code",
        "outputId": "a1acf1f4-d5fb-4737-dc79-76c47c9eab23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        }
      },
      "source": [
        "# For the 5th token in our sentence, select its feature values from layer 5.\n",
        "token_i = 5\n",
        "layer_i = 5\n",
        "vec = encoded_layers[layer_i][batch_i][token_i]\n",
        "\n",
        "# Plot the values as a histogram to show their distribution.\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.hist(vec, bins=200)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugEh6gRY1mji",
        "colab_type": "code",
        "outputId": "611df35a-42ae-4021-8aca-630ce82d3c02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "source": [
        "# `encoded_layers` is a Python list.\n",
        "print('     Type of encoded_layers: ', type(encoded_layers), len(encoded_layers))\n",
        "\n",
        "# Each layer in the list is a torch tensor.\n",
        "print('Tensor shape for each layer: ', encoded_layers[0].size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     Type of encoded_layers:  <class 'list'> 12\n",
            "Tensor shape for each layer:  torch.Size([1, 22, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cf0fid8L1pFi",
        "colab_type": "code",
        "outputId": "e6033dd1-40dc-4c64-88e2-7f69eb3b9fdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "# Concatenate the tensors for all layers. We use `stack` here to \n",
        "# create a new dimension in the tensor.\n",
        "token_embeddings = torch.stack(encoded_layers, dim=0)\n",
        "\n",
        "token_embeddings.size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([12, 1, 22, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aK4vOZQ21rAI",
        "colab_type": "code",
        "outputId": "32a973eb-e119-4caf-f66e-cfb885404a13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "# Remove dimension 1, the \"batches\".\n",
        "token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
        "\n",
        "token_embeddings.size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([12, 22, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtYoUCpx1tPn",
        "colab_type": "code",
        "outputId": "5736dbfd-57cf-41a4-a3cf-bb5baaddac78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "# Swap dimensions 0 and 1.\n",
        "token_embeddings = token_embeddings.permute(1, 0, 2)\n",
        "\n",
        "token_embeddings.size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([22, 12, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6QyfO9d1x3s",
        "colab_type": "text"
      },
      "source": [
        "### 3.3. Creating word and sentence vectors from hidden states"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXqaAtOU10cC",
        "colab_type": "text"
      },
      "source": [
        "**Word Vectors**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Egh2ZMlk14m7",
        "colab_type": "code",
        "outputId": "ae1210d0-0ca5-42e0-dcbf-97b7364184c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "# Stores the token vectors, with shape [22 x 3,072] (4 x 768 = 3,072)\n",
        "token_vecs_cat = []\n",
        "\n",
        "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
        "\n",
        "# For each token in the sentence...\n",
        "for token in token_embeddings:\n",
        "\n",
        "    # `token` is a [12 x 768] tensor\n",
        "\n",
        "    # Concatenate the vectors (that is, append them together) from the last four layers.\n",
        "    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
        "    cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
        "\n",
        "    # Use `cat_vec` to represent `token`.\n",
        "    token_vecs_cat.append(cat_vec)\n",
        "\n",
        "print('Shape is: %d x %d' % (len(token_vecs_cat), len(token_vecs_cat[0])))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape is: 22 x 3072\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUIfTF_918Kt",
        "colab_type": "code",
        "outputId": "b742bb97-246f-40a7-f89d-96c07a9ee160",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "# Stores the token vectors, with shape [22 x 768]\n",
        "token_vecs_sum = []\n",
        "\n",
        "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
        "\n",
        "# For each token in the sentence...\n",
        "for token in token_embeddings:\n",
        "\n",
        "    # `token` is a [12 x 768] tensor\n",
        "\n",
        "    # Sum the vectors from the last four layers.\n",
        "    sum_vec = torch.sum(token[-4:], dim=0)\n",
        "\n",
        "    # Use `sum_vec` to represent `token`.\n",
        "    token_vecs_sum.append(sum_vec)\n",
        "\n",
        "print('Shape is: %d x %d' % (len(token_vecs_sum), len(token_vecs_sum[0])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape is: 22 x 768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEUtWWdS19d_",
        "colab_type": "text"
      },
      "source": [
        "**Sentence Vectors**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUcAsKQQ2Bnc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# `encoded_layers` has shape [12 x 1 x 22 x 768]\n",
        "\n",
        "# `token_vecs` is a tensor with shape [22 x 768]\n",
        "token_vecs = encoded_layers[11][0]\n",
        "\n",
        "# Calculate the average of all 22 token vectors.\n",
        "sentence_embedding = torch.mean(token_vecs, dim=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOC48Pnn2DVW",
        "colab_type": "code",
        "outputId": "35f743de-c24d-4d47-d6cc-520cd40f1ebe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "print(\"Our final sentence embedding vector of shape:\", sentence_embedding.size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our final sentence embedding vector of shape: torch.Size([768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1rBPMwc2E_q",
        "colab_type": "text"
      },
      "source": [
        "### 3.4. Confirming contextually dependent vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CQwu6vS2HSy",
        "colab_type": "code",
        "outputId": "adb87b03-0d38-4ddb-c92b-3fa0a6b18b57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        }
      },
      "source": [
        "for i, token_str in enumerate(tokenized_text):\n",
        "    print(i, token_str)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 [CLS]\n",
            "1 after\n",
            "2 stealing\n",
            "3 money\n",
            "4 from\n",
            "5 the\n",
            "6 bank\n",
            "7 vault\n",
            "8 ,\n",
            "9 the\n",
            "10 bank\n",
            "11 robber\n",
            "12 was\n",
            "13 seen\n",
            "14 fishing\n",
            "15 on\n",
            "16 the\n",
            "17 mississippi\n",
            "18 river\n",
            "19 bank\n",
            "20 .\n",
            "21 [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chtciMQ92KR5",
        "colab_type": "code",
        "outputId": "12c58e4a-1c22-4f84-f24e-74e10a9e4764",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        }
      },
      "source": [
        "print('First 5 vector values for each instance of \"bank\".')\n",
        "print('')\n",
        "print(\"bank vault   \", str(token_vecs_sum[6][:5]))\n",
        "print(\"bank robber  \", str(token_vecs_sum[10][:5]))\n",
        "print(\"river bank   \", str(token_vecs_sum[19][:5]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First 5 vector values for each instance of \"bank\".\n",
            "\n",
            "bank vault    tensor([ 2.1319, -2.1413, -1.6260,  0.8638,  3.3173])\n",
            "bank robber   tensor([ 1.1868, -1.5298, -1.3770,  1.0648,  3.1446])\n",
            "river bank    tensor([ 1.1295, -1.4725, -0.7296, -0.0901,  2.4970])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noO7Imzt0UMQ",
        "colab_type": "code",
        "outputId": "21f0bb08-b376-44c4-ea71-011f6bdb0dea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "source": [
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "# Calculate the cosine similarity between the word bank\n",
        "# in \"bank robber\" vs \"river bank\" (different meanings).\n",
        "diff_bank = 1 - cosine(token_vecs_sum[10], token_vecs_sum[19])\n",
        "\n",
        "# Calculate the cosine similarity between the word bank\n",
        "# in \"bank robber\" vs \"bank vault\" (same meaning).\n",
        "same_bank = 1 - cosine(token_vecs_sum[10], token_vecs_sum[6])\n",
        "\n",
        "print('Vector similarity for  *similar*  meanings: %.2f' % same_bank)\n",
        "print('Vector similarity for *different* meanings: %.2f' % diff_bank)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vector similarity for  *similar*  meanings: 0.95\n",
            "Vector similarity for *different* meanings: 0.68\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7P4SRD42Lo9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}