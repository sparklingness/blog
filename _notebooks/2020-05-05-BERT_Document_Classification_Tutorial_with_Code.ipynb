{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2020-05-02-BERT Document Classification Tutorial with Code.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "830258b9784b453bb107ae35e9251adc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0d17e83adf55405a9f25cec34ba0b3df",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_65f3c1ee6a3147ccbd1e49fe42875900",
              "IPY_MODEL_499cc78cc5ff4bf7bd8b82d7187f8301"
            ]
          }
        },
        "0d17e83adf55405a9f25cec34ba0b3df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "65f3c1ee6a3147ccbd1e49fe42875900": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ff785394483b465bb7cf10cb8efcfe24",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_65cab788a0d84e97a61a0094cfa3988f"
          }
        },
        "499cc78cc5ff4bf7bd8b82d7187f8301": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_95c1e160c0154e1498a6d80958a66f01",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:51&lt;00:00, 4.49kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3dcfb2dfb62a40b695b9823d2f75db89"
          }
        },
        "ff785394483b465bb7cf10cb8efcfe24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "65cab788a0d84e97a61a0094cfa3988f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "95c1e160c0154e1498a6d80958a66f01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3dcfb2dfb62a40b695b9823d2f75db89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "417f42664d2849e689c02ca1543c51e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0a81eb8b1535423f8fe3d2b1230d3f85",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_686cda0af1574bec969f237bac80d328",
              "IPY_MODEL_fbdb96657af041cea5df84bd5bdfb99f"
            ]
          }
        },
        "0a81eb8b1535423f8fe3d2b1230d3f85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "686cda0af1574bec969f237bac80d328": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_64dd5c9ea43d40199e4d7a7298788478",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ddc00730143944c2aa5b22d2ddc13efd"
          }
        },
        "fbdb96657af041cea5df84bd5bdfb99f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_83826c3a18324b588c89d50b4e5396a4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [01:10&lt;00:00, 6.12B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6e36c64770a94099b5c64cdd141b6a91"
          }
        },
        "64dd5c9ea43d40199e4d7a7298788478": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ddc00730143944c2aa5b22d2ddc13efd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "83826c3a18324b588c89d50b4e5396a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6e36c64770a94099b5c64cdd141b6a91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e06f31d75f094d51beac92b3f6f14fd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8ae425e1daaa4d369bbfc2651c7af998",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a79d01067f3a4b3f9fb8b9c4bddd8d7a",
              "IPY_MODEL_7e91f60fb1c94ca2b661629b38ebbce2"
            ]
          }
        },
        "8ae425e1daaa4d369bbfc2651c7af998": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a79d01067f3a4b3f9fb8b9c4bddd8d7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ebe8874127c6474d901a7ae1396a7468",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_107a6f3afd6c4733937c5648b44e098b"
          }
        },
        "7e91f60fb1c94ca2b661629b38ebbce2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a9487cb255524bb5bf7923a236128320",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:45&lt;00:00, 9.62MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6db3980b85da4f81b0198cabd277dc6a"
          }
        },
        "ebe8874127c6474d901a7ae1396a7468": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "107a6f3afd6c4733937c5648b44e098b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a9487cb255524bb5bf7923a236128320": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6db3980b85da4f81b0198cabd277dc6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Scx3Rv9fWf_h",
        "colab_type": "text"
      },
      "source": [
        "# BERT Document Classification Tutorial\n",
        "> BERT Document Classification Tutorial  with Code\n",
        "> ref: https://colab.research.google.com/drive/1CfsGHuNWGGLg7ArPD_WE3sRuzFbDJav8#scrollTo=NxlZsafTC-V5\n",
        "\n",
        "- toc: true\n",
        "- branch: master\n",
        "- badges: true\n",
        "- comments: true\n",
        "- categories: [bert, jupyter]\n",
        "- hide: true\n",
        "- search_exclude: true"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXeq3NEBF8Rv",
        "colab_type": "text"
      },
      "source": [
        "# Classifying Wikipedia Comments with BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIlVLcMQF8Ou",
        "colab_type": "text"
      },
      "source": [
        "# Contents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_59-v5rFrdB",
        "colab_type": "text"
      },
      "source": [
        "# Part I - Setup & Dataset Prep"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXF93IIQH7O1",
        "colab_type": "text"
      },
      "source": [
        "## 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSlfWBV0IGQA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0437bd35-1368-41e2-abae-13382c1c30d9"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print(\"Found GPU at : {}\".format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at : /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUNK34-jI0Nx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "6556af40-b234-45e9-eed7-d3bf4854e799"
      },
      "source": [
        "%tensorflow_version"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Currently selected TF version: 2.x\n",
            "Available versions:\n",
            "* 1.x\n",
            "* 2.x\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMJ88WR4I30J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "78c4a7e8-7103-45e2-bec0-657aed327652"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available,\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    # Tell PyTorch to use the GPU.\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# IF not,\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-zROt3qI3uu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "outputId": "c3991ee4-9e6b-4eb8-c511-a20767495de0"
      },
      "source": [
        "! pip install transformers -q"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▋                               | 10kB 27.5MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20kB 32.8MB/s eta 0:00:01\r\u001b[K     |█▊                              | 30kB 36.7MB/s eta 0:00:01\r\u001b[K     |██▎                             | 40kB 37.1MB/s eta 0:00:01\r\u001b[K     |███                             | 51kB 40.2MB/s eta 0:00:01\r\u001b[K     |███▌                            | 61kB 42.6MB/s eta 0:00:01\r\u001b[K     |████                            | 71kB 40.2MB/s eta 0:00:01\r\u001b[K     |████▋                           | 81kB 40.6MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 92kB 41.8MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 102kB 42.4MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 112kB 42.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 122kB 42.4MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 133kB 42.4MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 143kB 42.4MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 153kB 42.4MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 163kB 42.4MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 174kB 42.4MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 184kB 42.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 194kB 42.4MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 204kB 42.4MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 215kB 42.4MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 225kB 42.4MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 235kB 42.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 245kB 42.4MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 256kB 42.4MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 266kB 42.4MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 276kB 42.4MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 286kB 42.4MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 296kB 42.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 307kB 42.4MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 317kB 42.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 327kB 42.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 337kB 42.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 348kB 42.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 358kB 42.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 368kB 42.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 378kB 42.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 389kB 42.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 399kB 42.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 409kB 42.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 419kB 42.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 430kB 42.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 440kB 42.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 450kB 42.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 460kB 42.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 471kB 42.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 481kB 42.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 491kB 42.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 501kB 42.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 512kB 42.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 522kB 42.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 532kB 42.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 542kB 42.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 552kB 42.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 563kB 42.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 573kB 42.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.0MB 49.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.7MB 50.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 36.4MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fz73ENp-H-db",
        "colab_type": "text"
      },
      "source": [
        "## 2. Retrieve & Inspect Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_mjokLcKMHM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "e70dc62b-3218-4a51-e74c-5df8e5105732"
      },
      "source": [
        "import urllib\n",
        "import os\n",
        "\n",
        "# Create the data subdirectory if not there.\n",
        "if not os.path.exists('./data/'):\n",
        "    os.mkdir('./data/')\n",
        "\n",
        "files = [\n",
        "         ('./data/attack_annotated_comments.tsv', 'https://ndownloader.figshare.com/files/7554634'),\n",
        "         ('./data/attack_annotations.tsv', 'https://ndownloader.figshare.com/files/7554637')\n",
        "]\n",
        "\n",
        "for (filename, url) in files:\n",
        "    # Download download if we don't already have it!\n",
        "    if not os.path.exists(filename):\n",
        "\n",
        "        # Download the dataset.\n",
        "        print('Downloading', filename)\n",
        "\n",
        "        urllib.request.urlretrieve(url, filename)\n",
        "\n",
        "        print('   DONE.')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading ./data/attack_annotated_comments.tsv\n",
            "   DONE.\n",
            "Downloading ./data/attack_annotations.tsv\n",
            "   DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTBnt3HnKL1q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2fda5166-663e-44f0-83ae-fe2627724e58"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "print('Parsing the dataset .tsv file...')\n",
        "comments = pd.read_csv('./data/attack_annotated_comments.tsv', sep='\\t', index_col = 0)\n",
        "annotations = pd.read_csv('./data/attack_annotations.tsv', sep='\\t')\n",
        "\n",
        "print('   Done.')"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parsing the dataset .tsv file...\n",
            "   Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BC0EOhSKLu1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "99ccc5c3-df1c-4c4b-aad5-5b3a25dd7fcd"
      },
      "source": [
        "# Display the first five rows of the table.\n",
        "comments.head()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>year</th>\n",
              "      <th>logged_in</th>\n",
              "      <th>ns</th>\n",
              "      <th>sample</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rev_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>37675</th>\n",
              "      <td>`-NEWLINE_TOKENThis is not ``creative``.  Thos...</td>\n",
              "      <td>2002</td>\n",
              "      <td>False</td>\n",
              "      <td>article</td>\n",
              "      <td>random</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44816</th>\n",
              "      <td>`NEWLINE_TOKENNEWLINE_TOKEN:: the term ``stand...</td>\n",
              "      <td>2002</td>\n",
              "      <td>False</td>\n",
              "      <td>article</td>\n",
              "      <td>random</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49851</th>\n",
              "      <td>NEWLINE_TOKENNEWLINE_TOKENTrue or false, the s...</td>\n",
              "      <td>2002</td>\n",
              "      <td>False</td>\n",
              "      <td>article</td>\n",
              "      <td>random</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89320</th>\n",
              "      <td>Next, maybe you could work on being less cond...</td>\n",
              "      <td>2002</td>\n",
              "      <td>True</td>\n",
              "      <td>article</td>\n",
              "      <td>random</td>\n",
              "      <td>dev</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93890</th>\n",
              "      <td>This page will need disambiguation.</td>\n",
              "      <td>2002</td>\n",
              "      <td>True</td>\n",
              "      <td>article</td>\n",
              "      <td>random</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  comment  year  ...  sample  split\n",
              "rev_id                                                           ...               \n",
              "37675   `-NEWLINE_TOKENThis is not ``creative``.  Thos...  2002  ...  random  train\n",
              "44816   `NEWLINE_TOKENNEWLINE_TOKEN:: the term ``stand...  2002  ...  random  train\n",
              "49851   NEWLINE_TOKENNEWLINE_TOKENTrue or false, the s...  2002  ...  random  train\n",
              "89320    Next, maybe you could work on being less cond...  2002  ...  random    dev\n",
              "93890                This page will need disambiguation.   2002  ...  random  train\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hexJsc9jKLnH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "outputId": "19e447e2-8fb4-4595-eb7f-dd0158a1d5df"
      },
      "source": [
        "comments[['comment', 'split']].groupby('split').count()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>split</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>dev</th>\n",
              "      <td>23160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test</th>\n",
              "      <td>23178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train</th>\n",
              "      <td>69526</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       comment\n",
              "split         \n",
              "dev      23160\n",
              "test     23178\n",
              "train    69526"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohhfR-PUKLho",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "b6e586cd-470b-460c-9851-f82e43a0c3a1"
      },
      "source": [
        "annotations.sample(5)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rev_id</th>\n",
              "      <th>worker_id</th>\n",
              "      <th>quoting_attack</th>\n",
              "      <th>recipient_attack</th>\n",
              "      <th>third_party_attack</th>\n",
              "      <th>other_attack</th>\n",
              "      <th>attack</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>107339</th>\n",
              "      <td>44745233</td>\n",
              "      <td>2584</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1225742</th>\n",
              "      <td>602195543</td>\n",
              "      <td>330</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1134782</th>\n",
              "      <td>534921976</td>\n",
              "      <td>478</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>964600</th>\n",
              "      <td>421581160</td>\n",
              "      <td>57</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199505</th>\n",
              "      <td>70323643</td>\n",
              "      <td>1893</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            rev_id  worker_id  ...  other_attack  attack\n",
              "107339    44745233       2584  ...           0.0     0.0\n",
              "1225742  602195543        330  ...           0.0     0.0\n",
              "1134782  534921976        478  ...           0.0     0.0\n",
              "964600   421581160         57  ...           0.0     0.0\n",
              "199505    70323643       1893  ...           0.0     1.0\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "un-ei8U9KLca",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Label a comment as an attack if the majority of annotators did so\n",
        "# The comments are uniquely identified by their 'rev_id'.  The annotations table\n",
        "# has multiple rows for each comment because there were multiple labelers.\n",
        "labels = annotations.groupby('rev_id')['attack'].mean() > 0.5\n",
        "\n",
        "# Join labels and comments\n",
        "comments['attack'] = labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDynOBJmO2rF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove newline and tab tokens\n",
        "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"NEWLINE_TOKEN\", \" \"))\n",
        "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"TAB_TOKEN\", \" \"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b838bbTsO2cK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fit a simple text classifier\n",
        "train_comments = comments.query(\"split=='train'\")\n",
        "test_comments = comments.query(\"split=='test'\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5osa7yjO2Vu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        },
        "outputId": "fe560a3f-f51d-4b3a-ece7-bee788ab8b16"
      },
      "source": [
        "import textwrap\n",
        "import random\n",
        "\n",
        "# Wrap text to 80 characters.\n",
        "wrapper = textwrap.TextWrapper(width=80)\n",
        "\n",
        "# Filter to just the \"attack\" comments.\n",
        "attack_examples = train_comments.query('attack')['comment']\n",
        "\n",
        "# Randomly choose some examples.\n",
        "for i in range(10):\n",
        "    j = random.choice(attack_examples.index)\n",
        "\n",
        "    print('')\n",
        "    print(wrapper.fill(attack_examples[j]))\n",
        "    print('')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "I SHOULD BE UNBANNED THIS INSTANT! GO TO HELL Android79!\n",
            "\n",
            "\n",
            "  == Booshakla ==  The guy was a sockpuppeteer here on Wikipedia. Quit acting\n",
            "like a cunt.\n",
            "\n",
            "\n",
            "  ====  FUCK YOU YOU PIECE OF SHIT! WHY THE FUCK HAVE YOU DELETED MY ARTICLES? I\n",
            "WILL REPORT YOU YOU FUCKING PIECE OF SHIT!\n",
            "\n",
            "\n",
            "  == douchebag ==  you're an asshole.  charlie.\n",
            "\n",
            "\n",
            "  == guess what ==  your retarded\n",
            "\n",
            "\n",
            "  ::you're right. allmusic is the last shit.\n",
            "\n",
            "\n",
            "` ::::::: It's not an encyclopedia.  Brittanica is an encyclopedia. Brittanica\n",
            "doesn't choose to employ [User:Essjay|lying pissants] as a reward for their\n",
            "duplicitous behavior.  This online ``encyclopedia``, you self-righteous inbred\n",
            "piece of shit, is a caricature.`\n",
            "\n",
            "\n",
            "   ::::::::::::::::::::::;WHAT THE FUCK IS WRONG WITH YOU PEOPLE? STOP CRITIZING\n",
            "US!!! YOU'RE WRITING IN OPINION!! FUCK STOP THIS! MADDOX IS A PRICK\n",
            "\n",
            "\n",
            "  The Greater San Francisco Bay Area is greater than the typical Bay Area\n",
            "Definition you idiot stop reverting my edits until YOU have sources obviously\n",
            "like every other metro area a greater region is obviously bigger you idiot. Go\n",
            "shove your internet awards some where because they dont matter when all you do\n",
            "is type on a key board.\n",
            "\n",
            "\n",
            "`  == Why ==  Why are you so stupid?   `\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvuX95RYUqOj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f018e087-3e72-41c3-d573-99624c953686"
      },
      "source": [
        "total_comments = len(comments)\n",
        "num_attacks = len(comments.query('attack'))\n",
        "\n",
        "print('{:,} of {:,} comments are attacks ({:.2%})'.format(num_attacks, total_comments, num_attacks/total_comments))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13,590 of 115,864 comments are attacks (11.73%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpuvtjHJUp_D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "a333a0ef-4ab0-410c-b618-778acef918ef"
      },
      "source": [
        "prcnt_non_attack = 1 - (len(test_comments.query('attack')) / len(test_comments))\n",
        "\n",
        "print('Always predicting \"not attack\" will yeild {:.2%} accuracy on the test set.'.format(prcnt_non_attack))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Always predicting \"not attack\" will yeild 88.11% accuracy on the test set.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eXYQ5iGICML",
        "colab_type": "text"
      },
      "source": [
        "## 3. BERT Input Length Limitation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NP69fPDQWKK0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "830258b9784b453bb107ae35e9251adc",
            "0d17e83adf55405a9f25cec34ba0b3df",
            "65f3c1ee6a3147ccbd1e49fe42875900",
            "499cc78cc5ff4bf7bd8b82d7187f8301",
            "ff785394483b465bb7cf10cb8efcfe24",
            "65cab788a0d84e97a61a0094cfa3988f",
            "95c1e160c0154e1498a6d80958a66f01",
            "3dcfb2dfb62a40b695b9823d2f75db89"
          ]
        },
        "outputId": "bc88e070-53f9-493a-d147-723646569ae8"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "830258b9784b453bb107ae35e9251adc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRugtrR2WKEa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 801
        },
        "outputId": "c55b96cb-0ec2-4df6-fc61-e7aa80484507"
      },
      "source": [
        "# Retrieve the text of the first comment.\n",
        "text = train_comments.iloc[0].comment\n",
        "\n",
        "# Run the tokenizer to count up the number of tokens. The tokenizer will split\n",
        "# the text into words, punctuation, and subwords as needed.\n",
        "tokens = tokenizer.tokenize(text)\n",
        "\n",
        "print('Comment 0 (not an attack) contains {:,} WordPiece tokens.'.format(len(tokens)))\n",
        "print('\\nOriginal comment text:\\n')\n",
        "print(wrapper.fill(text))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Comment 0 (not an attack) contains 591 WordPiece tokens.\n",
            "\n",
            "Original comment text:\n",
            "\n",
            "`- This is not ``creative``.  Those are the dictionary definitions of the terms\n",
            "``insurance`` and ``ensurance`` as properly applied to ``destruction``.  If you\n",
            "don't understand that, fine, legitimate criticism, I'll write up ``three man\n",
            "cell`` and ``bounty hunter`` and then it will be easy to understand why\n",
            "``ensured`` and ``insured`` are different - and why both differ from\n",
            "``assured``.  The sentence you quote is absolutely neutral.  You just aren't\n",
            "familiar with the underlying theory of strike-back (e.g. submarines as employed\n",
            "in nuclear warfare) guiding the insurance, nor likely the three man cell\n",
            "structure that kept the IRA from being broken by the British.  If that's my\n",
            "fault, fine, I can fix that to explain.  But ther'es nothing ``personal`` or\n",
            "``creative`` about it.  I'm tired of arguing with you.  Re: the other article,\n",
            "``multi-party`` turns up plenty, and there is more use of ``mutually`` than\n",
            "``mutual``.  If I were to apply your standard I'd be moving ``Mutual Assured\n",
            "Destruction`` to ``talk`` for not appealing to a Reagan voter's biases about its\n",
            "effectiveness, and for dropping the ``ly``.  There is a double standard in your\n",
            "edits.  If it comes from some US history book, like ``peace movement`` or\n",
            "'M.A.D.' as defined in 1950, you like it, even if the definition is totally\n",
            "useless in 2002 and only of historical interest.    If it makes any even-obvious\n",
            "connection or implication from the language chosen in multiple profession-\n",
            "specific terms, you consider it somehow non-neutral...  Gandhi thinks ``eye for\n",
            "an eye`` describes riots, death penalty, and war all at once, but you don't.\n",
            "What do you know that Gandhi doesn't?  Guess what:  reality is not neutral.\n",
            "Current use of terms is slightly more controversial.  Neutrality requires\n",
            "negotiation, and some willingness to learn.  This is your problem not mine.  You\n",
            "may dislike the writing, fine, that can be fixed.  But disregarding fundamental\n",
            "axioms of philosphy with names that recur in multiple phrases, or failing to\n",
            "make critical distinctions like 'insurance' versus 'assurance' versus\n",
            "'ensurance' (which are made in one quote by an Air Force general in an in-\n",
            "context quote), is just a disservice to the reader.  If someone comes here to\n",
            "research a topic like MAD, they want some context, beyond history.  If this is a\n",
            "history book, fine, it's a history book.  But that wasn't what it was claimed to\n",
            "be... `\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-l-8vvP_WJ8d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 888
        },
        "outputId": "e57007d4-f84e-4e1a-8577-ee0e88cc48e8"
      },
      "source": [
        "# Print out the list of tokens\n",
        "print('==== First 512 tokens: ====\\n')\n",
        "print(wrapper.fill(str(' '.join(tokens[0:512]))))\n",
        "\n",
        "print('')\n",
        "\n",
        "print('\\n==== Remaining {:,} tokens: ====\\n'.format(len(tokens) - 512))\n",
        "print(wrapper.fill(str(' '.join(tokens[512:]))))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==== First 512 tokens: ====\n",
            "\n",
            "` - this is not ` ` creative ` ` . those are the dictionary definitions of the\n",
            "terms ` ` insurance ` ` and ` ` en ##sur ##ance ` ` as properly applied to ` `\n",
            "destruction ` ` . if you don ' t understand that , fine , legitimate criticism ,\n",
            "i ' ll write up ` ` three man cell ` ` and ` ` bounty hunter ` ` and then it\n",
            "will be easy to understand why ` ` ensured ` ` and ` ` ins ##ured ` ` are\n",
            "different - and why both differ from ` ` assured ` ` . the sentence you quote is\n",
            "absolutely neutral . you just aren ' t familiar with the underlying theory of\n",
            "strike - back ( e . g . submarines as employed in nuclear warfare ) guiding the\n",
            "insurance , nor likely the three man cell structure that kept the ira from being\n",
            "broken by the british . if that ' s my fault , fine , i can fix that to explain\n",
            ". but the ##r ' es nothing ` ` personal ` ` or ` ` creative ` ` about it . i ' m\n",
            "tired of arguing with you . re : the other article , ` ` multi - party ` ` turns\n",
            "up plenty , and there is more use of ` ` mutually ` ` than ` ` mutual ` ` . if i\n",
            "were to apply your standard i ' d be moving ` ` mutual assured destruction ` `\n",
            "to ` ` talk ` ` for not appealing to a reagan voter ' s bias ##es about its\n",
            "effectiveness , and for dropping the ` ` l ##y ` ` . there is a double standard\n",
            "in your edit ##s . if it comes from some us history book , like ` ` peace\n",
            "movement ` ` or ' m . a . d . ' as defined in 1950 , you like it , even if the\n",
            "definition is totally useless in 2002 and only of historical interest . if it\n",
            "makes any even - obvious connection or implication from the language chosen in\n",
            "multiple profession - specific terms , you consider it somehow non - neutral . .\n",
            ". gandhi thinks ` ` eye for an eye ` ` describes riots , death penalty , and war\n",
            "all at once , but you don ' t . what do you know that gandhi doesn ' t ? guess\n",
            "what : reality is not neutral . current use of terms is slightly more\n",
            "controversial . neutrality requires negotiation , and some willingness to learn\n",
            ". this is your problem not mine . you may dislike the writing , fine , that can\n",
            "be fixed . but disregard ##ing fundamental ax ##ioms of phil ##os ##phy with\n",
            "names that rec ##ur in multiple phrases , or failing to make critical\n",
            "distinctions like ' insurance ' versus ' assurance ' versus ' en ##sur ##ance '\n",
            "( which\n",
            "\n",
            "\n",
            "==== Remaining 79 tokens: ====\n",
            "\n",
            "are made in one quote by an air force general in an in - context quote ) , is\n",
            "just a di ##sser ##vic ##e to the reader . if someone comes here to research a\n",
            "topic like mad , they want some context , beyond history . if this is a history\n",
            "book , fine , it ' s a history book . but that wasn ' t what it was claimed to\n",
            "be . . . `\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TMSW7PpWJ1i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "85f8a51f-5004-484f-83bd-975d5d670a96"
      },
      "source": [
        "# First truncate the text to remove the last 79 tokens (which begin with the words \"are made in\").\n",
        "last_char = text.find('are made in')\n",
        "\n",
        "# Trancate the text to only what fits in the 512 tokens.\n",
        "text = text[:last_char]\n",
        "\n",
        "# Estimate the number of words in the comment by splitting it on whitespace.\n",
        "# First remove all double spaces.\n",
        "text = text.replace('  ', ' ')\n",
        "num_words = len(text.split(' '))\n",
        "\n",
        "print('Comment contains ~{:,} words.'.format(num_words))\n",
        "\n",
        "# Estimate the number of sentences by counting up the periods.\n",
        "num_sens = text.count('. ')\n",
        "\n",
        "print('Comment contains ~{:,} sentences.'.format(num_sens))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Comment contains ~330 words.\n",
            "Comment contains ~20 sentences.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7ov7UHlWJlH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "61d27d77-3778-4c06-8bd9-e1fbe7c7cac6"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to their word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# Record the length of each sequence (after truncating to 512).\n",
        "lengths = []\n",
        "\n",
        "print('Tokenizing comments...')\n",
        "\n",
        "# For every sentence,\n",
        "for sen in train_comments.comment:\n",
        "\n",
        "    # Report progress.\n",
        "    if ((len(input_ids) % 20000) == 0):\n",
        "        print('  Read {:,} comments.'.format(len(input_ids)))\n",
        "\n",
        "    # `encode` will:\n",
        "    #    (1) Tokenize the sentence.\n",
        "    #    (2) Prepend the `[CLS]` token to the start.\n",
        "    #    (3) Append the `[SEP]` token to the end.\n",
        "    #    (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "        sen,                                        # Sentence to encode.\n",
        "        add_special_tokens = True,      # Add [CLS]' and '[SEP]'\n",
        "        #max_length = 512,                  # Truncate all sentences.\n",
        "        #return_tensors = 'pt',             # Return pytorch tensors.\n",
        "    )\n",
        "\n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "    # Record the truncated length.\n",
        "    lengths.append(len(encoded_sent))\n",
        "\n",
        "print('DONE.')\n",
        "print('{:>10,} comments'.format(len(input_ids)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (591 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (541 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tokenizing comments...\n",
            "  Read 0 comments.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1088 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (593 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1057 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (791 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (608 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (877 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (729 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1029 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1032 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (662 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (617 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1886 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (652 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (546 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (903 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (611 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (962 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1007 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (616 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (629 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1091 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1061 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1698 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1002 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1045 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (634 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (622 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (577 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (537 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1072 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1092 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (794 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (963 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (976 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (838 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (801 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1954 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (964 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (548 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (601 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (626 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (892 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (697 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1999 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (795 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (568 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (682 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (657 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (957 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (614 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1002 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1316 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2210 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2243 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1345 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1100 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (847 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (612 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1285 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (627 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (620 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1107 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2226 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2108 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (559 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1658 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (954 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (986 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (557 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (577 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (594 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1029 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1046 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (942 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2303 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (872 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (669 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1067 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1175 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1175 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1177 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (570 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (686 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (638 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1463 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (558 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (915 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (848 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1490 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1483 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1124 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (912 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1238 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1176 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1198 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2062 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1285 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1074 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1159 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1273 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1069 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (917 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (932 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1011 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (601 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (619 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1098 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1132 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (562 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (884 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (997 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (747 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (804 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1063 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1326 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2526 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1703 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1338 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (782 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (806 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (719 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (728 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (903 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1993 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (711 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1001 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1114 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (894 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (862 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (708 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (730 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1089 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1513 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (780 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (895 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3810 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (545 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1034 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (537 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (617 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (636 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (579 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (760 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1872 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (597 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (650 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1196 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (979 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (624 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1498 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1519 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3125 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1500 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1095 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (544 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (844 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3368 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (600 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1860 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (588 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (613 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (864 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1261 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (559 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1691 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (648 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (576 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (891 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1850 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (544 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (573 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1685 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2128 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (704 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (581 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (787 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (742 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (933 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (534 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (633 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (795 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (646 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (617 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (653 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1040 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2065 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (608 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1304 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2559 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1054 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (603 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (760 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (876 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2643 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1334 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (599 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1005 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1582 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (511 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (647 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1141 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (649 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (663 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2857 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (816 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1097 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1126 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (630 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1009 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2110 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (649 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1013 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (665 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (601 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1747 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1036 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1339 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (665 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (770 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1856 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (615 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (978 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (563 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1102 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (896 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (934 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1022 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (664 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (671 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (611 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (621 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (628 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (798 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1043 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2858 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (664 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (974 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (623 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (749 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (966 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (663 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (582 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (572 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (857 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (611 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (908 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (856 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1002 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (836 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (732 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (929 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (579 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1082 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2219 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2223 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (665 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (790 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (622 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (9322 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3078 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1401 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2031 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (760 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (920 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1907 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1905 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1903 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (571 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (653 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (929 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3624 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (918 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1022 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (552 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (652 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2698 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (794 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (977 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2253 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1747 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1743 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (741 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (540 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1473 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (566 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1749 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1257 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (986 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (615 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (546 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (556 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1197 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (844 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (553 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (565 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1021 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1473 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (824 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (870 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1236 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (588 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1109 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (609 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (675 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (944 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (650 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (562 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (896 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1467 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (972 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (670 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (838 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1284 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1122 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1084 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (640 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (928 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1718 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (739 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1093 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1273 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1351 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (912 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (748 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (637 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (785 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (764 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1671 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (959 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (642 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (884 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (638 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (640 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1218 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1167 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (534 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1144 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (522 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (530 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (726 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (832 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (870 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (857 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (911 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (911 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1012 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1154 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (873 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (888 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1229 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (904 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (939 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (618 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1867 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2325 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (587 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1017 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2173 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (655 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (846 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1012 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (836 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1156 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1802 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (837 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (907 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (707 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1181 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (849 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (568 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (845 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1012 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (785 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (805 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1015 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (632 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (909 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (878 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3130 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (849 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2102 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (705 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (556 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (563 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (911 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (925 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (814 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1556 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1666 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1038 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1036 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1927 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (663 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2089 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (820 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (663 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (656 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (800 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1091 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1578 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (819 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (566 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (754 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (548 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (552 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (970 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (819 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1086 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1338 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2496 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (4204 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (4559 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (909 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (971 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1044 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (886 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1235 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1173 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (663 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (737 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (899 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1650 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1273 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (689 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (888 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (879 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1033 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (721 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (817 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (692 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1385 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (930 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1528 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1098 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (815 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (805 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1944 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (966 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2049 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (690 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (875 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1746 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (780 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (907 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1317 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (953 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (673 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (625 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (819 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1113 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (660 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (943 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (627 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1004 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2106 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1950 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (986 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (668 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (512 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2391 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (925 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1225 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2095 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (952 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (744 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (559 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1085 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (766 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (635 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1306 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1320 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (983 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1302 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2507 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1737 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1113 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (962 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (523 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (878 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1121 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (619 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (526 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1158 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2430 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (535 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1747 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (593 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (777 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1036 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (745 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (602 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1650 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Read 20,000 comments.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (548 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (959 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (683 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (526 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1074 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1078 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (978 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (609 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1648 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (586 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (665 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (669 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1182 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (989 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (650 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1082 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (646 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (872 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (742 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (747 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (570 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (522 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (935 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (530 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1364 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1256 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (984 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (562 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1054 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (954 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (984 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1145 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (785 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1037 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1599 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (890 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1101 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (576 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (853 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1114 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (864 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (565 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (689 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1194 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (878 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1054 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (768 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (937 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (584 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (996 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (821 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1390 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1115 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1176 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (729 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (677 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (584 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (580 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1559 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1500 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (684 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (804 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (816 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (881 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1354 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (599 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1987 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (647 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2252 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1968 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (944 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1133 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1219 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2200 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1481 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (829 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (869 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3333 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2858 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (9859 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (720 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (758 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (602 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (604 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (611 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1011 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1636 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (715 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1638 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (777 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (4962 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (569 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (693 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (653 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (624 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (584 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (910 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1728 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2495 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (842 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (929 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1183 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (591 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3750 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1643 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2046 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2042 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (736 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (588 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (531 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (530 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1165 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (915 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (674 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (662 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1047 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1763 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1607 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1123 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1132 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (580 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (851 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (545 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (734 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (530 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (582 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1142 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (875 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (554 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (767 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1687 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (932 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1064 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (698 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (615 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (644 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (624 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (522 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (860 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (988 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1914 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (560 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (895 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (534 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3118 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (545 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2106 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (536 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (534 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (552 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1874 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1631 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (903 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1201 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (679 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3364 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3155 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1978 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2088 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1982 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (511 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (561 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (618 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (978 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (750 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (553 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1516 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1676 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (959 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1916 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1865 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (529 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (691 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1248 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (989 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (609 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (632 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1195 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1664 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (931 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (593 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (923 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (535 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1492 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (587 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1449 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (946 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1797 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (999 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (602 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (860 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (783 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (599 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (929 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (692 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (628 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (993 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2224 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2853 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (548 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2275 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2503 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2497 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1888 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2199 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (730 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2248 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (689 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (805 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3750 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1054 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2055 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1876 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (818 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1685 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1107 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (829 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (648 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1014 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1017 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (645 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (664 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (729 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1094 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (906 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (758 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (710 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2133 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1862 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1004 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (927 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2071 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (815 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1702 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (567 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (678 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (854 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (587 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (707 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (638 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (886 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (861 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (975 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (737 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (871 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (975 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (581 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1774 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (814 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (744 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3995 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (658 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2207 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1459 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (934 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (949 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (829 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (889 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1035 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1047 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1486 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1089 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1671 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (853 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1571 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1888 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1571 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (985 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (623 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1073 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (625 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (733 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2211 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (631 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (632 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (611 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (950 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (920 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (765 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (696 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1536 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1058 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1085 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (895 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (666 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2218 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1040 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (683 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2312 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1218 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (928 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1112 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1190 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1098 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (731 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1055 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1766 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1051 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1992 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (795 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (985 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1092 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2331 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (686 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (592 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1423 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (691 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (689 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1442 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (995 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1175 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (826 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (618 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1526 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1267 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1062 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1374 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (559 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1137 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2020 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3985 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (677 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (793 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (746 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (621 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1278 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1120 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (770 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (670 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (842 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (923 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (939 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (760 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2000 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3125 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (599 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (656 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1034 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3153 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2956 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1226 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1056 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (580 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (786 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1068 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (910 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1425 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (886 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (694 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (749 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (644 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (807 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3340 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1388 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (687 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1137 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (754 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (619 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (796 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2099 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1151 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1428 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (751 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (597 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (990 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1078 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (858 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (724 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (791 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (902 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1277 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (529 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1804 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (861 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (530 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1396 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (603 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (526 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (580 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (815 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2307 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (602 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (568 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1066 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (865 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1007 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1008 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (4239 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (800 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1107 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1078 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1520 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1441 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (910 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1245 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (985 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (613 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (700 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (884 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1577 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (781 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (973 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1079 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (856 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (847 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2170 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (843 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (879 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (816 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (629 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1002 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (665 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (575 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (639 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (688 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (971 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (695 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (626 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (640 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (883 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (682 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1046 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (905 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (511 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (524 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (932 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2223 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (807 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (668 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2121 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (858 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (680 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (736 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (588 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (842 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (840 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (761 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (546 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2723 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1000 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1108 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (826 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (760 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (577 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (619 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (588 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (748 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (875 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2060 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1792 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (639 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1250 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1477 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (704 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (593 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (624 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (827 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (644 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (980 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1034 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (4000 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3333 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1256 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (511 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2494 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1380 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2300 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1298 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2210 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (569 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (615 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1096 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1581 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1397 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1467 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (661 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (703 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (615 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (982 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1001 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (569 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1083 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (704 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (803 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Read 40,000 comments.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (629 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (588 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2054 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2041 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2037 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2040 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1079 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (668 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (641 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (726 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1028 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1809 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (560 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (931 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1065 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1124 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (646 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (589 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1177 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (795 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (803 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (878 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (554 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (554 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (812 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (563 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (559 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (615 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (603 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2351 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (726 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (745 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (549 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (792 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (614 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (736 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2282 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (749 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (795 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (836 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (789 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (560 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1653 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (844 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1509 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1509 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (845 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (745 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2255 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (617 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1724 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1000 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1324 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1086 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1203 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1011 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (805 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (723 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (766 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (559 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (529 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (836 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (4283 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (699 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (614 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (973 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (652 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (832 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (686 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (567 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (936 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1173 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (819 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (614 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (588 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (730 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1161 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (833 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (555 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (661 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (672 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (985 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2497 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (4082 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (835 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (512 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (632 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (536 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (836 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (792 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (713 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (913 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (606 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (536 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (559 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (899 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1162 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (581 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1117 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (806 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (596 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (919 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (835 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1043 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (540 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3333 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3182 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (723 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1934 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1195 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (552 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (539 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1348 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1046 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1000 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (552 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (739 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (971 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1044 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (619 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (777 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1762 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (696 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (522 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1581 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (656 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (607 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (580 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (721 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (548 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (995 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (990 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1555 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (626 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (567 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (604 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (807 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (661 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (833 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1571 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (719 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1782 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1561 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (807 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (895 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1093 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1589 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1681 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (940 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (729 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (896 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (566 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (637 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (793 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1090 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (815 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (769 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1620 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (959 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1146 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (611 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1151 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1620 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (543 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1007 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1039 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2173 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (911 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (990 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (781 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1051 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1114 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1473 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (908 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1753 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (953 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2128 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (713 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (969 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2098 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1100 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2492 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (810 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (776 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (543 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1023 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (541 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (526 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (567 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (598 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2657 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2657 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (534 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1166 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (578 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (850 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1616 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (615 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (535 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (617 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (723 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (647 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1049 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1902 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1025 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (595 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (829 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2068 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (861 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1139 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (566 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2117 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (536 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (698 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1115 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (588 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2677 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (958 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (793 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (872 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1162 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (878 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (711 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (749 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (707 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (896 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (752 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (653 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (796 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (801 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (820 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1677 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (566 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (596 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (675 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (678 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (808 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (843 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (913 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (904 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (697 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1894 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (705 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (610 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (841 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2058 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2549 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1638 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (640 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1025 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (543 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (606 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (653 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (976 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (627 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (511 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (728 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (651 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1825 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (852 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (631 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1133 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (897 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2667 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (788 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (913 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2191 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (563 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (766 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (757 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1042 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (551 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1370 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (569 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (575 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (771 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (635 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (822 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (575 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1077 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (596 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (958 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (582 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (822 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1553 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (536 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (553 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1876 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1872 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (623 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (903 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1383 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (755 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (939 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (572 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (632 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (721 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (553 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (674 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (575 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (523 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (575 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (573 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (668 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1034 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (575 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (578 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (772 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (952 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1743 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (553 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (729 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1574 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (564 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (781 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2183 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (794 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (619 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (620 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (988 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (985 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (925 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (880 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (576 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (911 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (576 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1431 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1312 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (563 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (671 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (820 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1483 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (709 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2625 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (555 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (576 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1482 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (576 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (632 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (696 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (592 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (598 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (832 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1274 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (716 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1258 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (999 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1573 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (708 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1685 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (772 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1029 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1845 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (537 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1161 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (779 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1326 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (522 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1402 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (911 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (672 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (910 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (561 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (582 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (603 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1277 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (610 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (779 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1091 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (676 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (763 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (711 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1520 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (853 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (599 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (585 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1162 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1012 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (740 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (958 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1001 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (712 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (626 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (780 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (512 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (652 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (558 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1209 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (599 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (663 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (595 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Read 60,000 comments.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (522 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (624 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1002 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1398 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (718 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (585 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1077 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (734 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (596 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (861 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (906 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (566 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (551 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1017 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (557 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2072 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1040 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2343 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (803 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (570 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (678 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (553 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (616 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (644 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (777 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (787 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (703 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (689 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (679 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (623 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (567 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (728 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (771 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1197 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1064 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2730 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2021 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1590 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1605 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (798 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (884 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (945 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (543 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (672 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1040 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (994 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1197 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1690 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1743 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (545 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1602 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (954 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1138 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (936 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (655 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (587 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1168 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (576 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (512 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (958 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1009 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (780 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (639 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1100 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (722 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (741 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (621 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (703 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (628 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (682 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (545 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (625 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (751 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (657 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (657 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (553 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (719 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (543 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (616 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1968 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (975 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (943 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (626 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (552 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1373 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2147 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1693 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1135 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (597 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (718 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (829 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (580 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (936 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (714 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (953 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (647 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1806 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (619 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (546 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2066 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2622 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (736 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (848 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (624 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (690 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (801 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (801 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (875 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (952 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (685 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (853 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (587 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (636 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2209 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2644 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (626 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (571 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (602 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (757 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (685 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1290 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1124 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1496 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (580 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (576 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (585 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (735 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (965 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (716 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (582 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1149 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (619 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (697 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (964 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (584 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (559 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (579 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1308 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (990 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (654 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (699 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (529 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (750 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (961 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1064 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1151 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (607 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (680 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (627 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (552 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (872 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (635 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1270 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (581 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (549 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (643 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (823 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (571 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (731 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (590 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1079 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (792 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (816 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (826 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (979 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (681 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (991 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1384 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (930 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1041 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (865 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (874 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (661 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (861 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1330 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1113 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1033 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (615 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (859 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (581 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2203 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1755 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1063 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (635 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (628 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (710 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (884 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (831 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (855 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1080 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1327 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (918 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (705 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (734 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (592 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (531 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (950 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1088 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (697 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DONE.\n",
            "    69,526 comments\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xbqo8qSx1qa0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "81583a67-b1d5-45d9-82ce-f9e498ae0b8f"
      },
      "source": [
        "# Also retrieve the labels as a list.\n",
        "\n",
        "# Get the labels from the DataFrame, and conver from booleans to ints.\n",
        "labels = train_comments.attack.to_numpy().astype(int)\n",
        "\n",
        "print('{:>7,} positive (contains attack)'.format(np.sum(labels)))\n",
        "print('{:>7,} negative (not an attack)'.format(len(labels) - np.sum(labels)))\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  8,079 positive (contains attack)\n",
            " 61,447 negative (not an attack)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpdXOlSr1qKm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "9604922e-3508-4bf2-f967-5ce608a59987"
      },
      "source": [
        "print('   Min length: {:,} tokens'.format(min(lengths)))\n",
        "print('   Max length: {:,} tokens'.format(max(lengths)))\n",
        "print('Median length: {:,} tokens'.format(np.median(lengths)))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Min length: 2 tokens\n",
            "   Max length: 9,861 tokens\n",
            "Median length: 52.0 tokens\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kRVQDqV1p0B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604
        },
        "outputId": "5fb41308-7c3b-46d8-9eac-d4530c34d4d3"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (10,5)\n",
        "\n",
        "# Truncate any comment lengths greater than 512.\n",
        "lengths = [min(l, 512) for l in lengths]\n",
        "\n",
        "# Plot the distribution of comment lengths.\n",
        "sns.distplot(lengths, kde=False, rug=False)\n",
        "\n",
        "# Alternatively, you might try using a log scale on the x-axis, but this is tricky.\n",
        "# See here for one approach:\n",
        "# https://stackoverflow.com/questions/47850202/plotting-a-histogram-on-a-log-scale-with-matplotlib?rq=1\n",
        "# plt.xscale('log')\n",
        "\n",
        "plt.title('Comment Lengths')\n",
        "plt.xlabel('Comment Length')\n",
        "plt.ylabel('# of Comments')\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, '# of Comments')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLwNWuRC_Zh5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "91dce5f3-30e0-4739-b767-2412164096e6"
      },
      "source": [
        "# Count the number of sentences that had to be truncated to 512 tokens.\n",
        "num_truncated = lengths.count(512)\n",
        "\n",
        "# Compare this to the total number of training sentences.\n",
        "num_sentences = len(lengths)\n",
        "prcnt = float(num_truncated) / float(num_sentences)\n",
        "\n",
        "print('{:,} of {:,} sentences ({:.1%}) in the training set are longer than 512 tokens.'.format(num_truncated, num_sentences, prcnt))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1,668 of 69,526 sentences (2.4%) in the training set are longer than 512 tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuxemeIS_ZKO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "11caac08-7052-4152-e374-7e078354e0ae"
      },
      "source": [
        "# Tally up how many of the truncated sentences are positive vs. negative examples.\n",
        "num_pos = 0\n",
        "num_neg = 0\n",
        "\n",
        "# Iterate through the comment lengths,\n",
        "for i, l in enumerate(lengths):\n",
        "\n",
        "    # If the sentence was truncated,\n",
        "    if l == 512:\n",
        "\n",
        "        # Tally up whether it contains a personal attack or not.\n",
        "        if labels[l] == 1:\n",
        "            num_pos += 1\n",
        "        else:\n",
        "            num_neg += 1\n",
        "    \n",
        "# Report the total.\n",
        "print('{:,} ({:.1%}) of the truncated examples contain a personal attack'.format(num_pos, num_pos / (num_neg + num_pos)))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 (0.0%) of the truncated examples contain a personal attack\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktZLt0QP_Y9f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "9c2e1905-6773-4a45-ac17-0910a3f23ad0"
      },
      "source": [
        "# We'll borrow the `pad_sequences` utility function to do this.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the required sequnce length.\n",
        "MAX_LEN = 128\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\",\n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Padding/truncating all sentences to 128 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fqj-O4p4GqQK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "outputId": "14a3d1d6-16a1-4a63-9fdc-b646ea69e444"
      },
      "source": [
        "input_ids[0]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  101,  1036,  1011,  2023,  2003,  2025,  1036,  1036,  5541,\n",
              "        1036,  1036,  1012,  2216,  2024,  1996,  9206, 15182,  1997,\n",
              "        1996,  3408,  1036,  1036,  5427,  1036,  1036,  1998,  1036,\n",
              "        1036,  4372, 26210,  6651,  1036,  1036,  2004,  7919,  4162,\n",
              "        2000,  1036,  1036,  6215,  1036,  1036,  1012,  2065,  2017,\n",
              "        2123,  1005,  1056,  3305,  2008,  1010,  2986,  1010, 11476,\n",
              "        6256,  1010,  1045,  1005,  2222,  4339,  2039,  1036,  1036,\n",
              "        2093,  2158,  3526,  1036,  1036,  1998,  1036,  1036, 17284,\n",
              "        4477,  1036,  1036,  1998,  2059,  2009,  2097,  2022,  3733,\n",
              "        2000,  3305,  2339,  1036,  1036, 16316,  1036,  1036,  1998,\n",
              "        1036,  1036, 16021, 12165,  1036,  1036,  2024,  2367,  1011,\n",
              "        1998,  2339,  2119, 11234,  2013,  1036,  1036,  8916,  1036,\n",
              "        1036,  1012,  1996,  6251,  2017, 14686,  2003,  7078,  8699,\n",
              "        1012,  2017,  2074,  4995,  1005,  1056,  5220,  2007,  1996,\n",
              "       10318,  3399])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tDetmv7_Yo_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "outputId": "3748d371-0df7-4356-a50b-42976a280197"
      },
      "source": [
        "input_ids[2]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  101,  2995,  2030,  6270,  1010,  1996,  3663,  2004,  1997,\n",
              "        2233,  2526,  2001,  2107,  1024,  1037,  8174,  6378,  1997,\n",
              "        2455,  2005,  3521,  1998,  5038,  2011,  2035,  5424,  3032,\n",
              "        2001,  2081,  1012,  1996,  2154,  1996,  6378,  2001,  2000,\n",
              "        2022,  2081,  5337,  2011,  1996,  5424,  2223,  2001,  1996,\n",
              "        2154,  1996,  5611,  1005,  1055,  2104,  1996,  3094,  1997,\n",
              "       16126, 10666,  2211,  1996,  5274,  1997,  1996,  9302,  2969,\n",
              "        1011,  3627,  2752,  1012,  5310,  1024,  5424,  1012,   102,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frPT3OdzHXRR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence,\n",
        "for sent in input_ids:\n",
        "\n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "\n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFQ7x1hQHXCg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for training\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 90% for training and 10% for validation.\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, random_state=2018, test_size=0.1)\n",
        "\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels, random_state=2018, test_size = 0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9gw3UetHW0n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJtKNC81HWqo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32.\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t86padpqFrJP",
        "colab_type": "text"
      },
      "source": [
        "# Part II - BERT Fine-Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBwShO1CQSpn",
        "colab_type": "text"
      },
      "source": [
        "## Train Our Classification Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WmiedCHQylY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "417f42664d2849e689c02ca1543c51e6",
            "0a81eb8b1535423f8fe3d2b1230d3f85",
            "686cda0af1574bec969f237bac80d328",
            "fbdb96657af041cea5df84bd5bdfb99f",
            "64dd5c9ea43d40199e4d7a7298788478",
            "ddc00730143944c2aa5b22d2ddc13efd",
            "83826c3a18324b588c89d50b4e5396a4",
            "6e36c64770a94099b5c64cdd141b6a91",
            "e06f31d75f094d51beac92b3f6f14fd0",
            "8ae425e1daaa4d369bbfc2651c7af998",
            "a79d01067f3a4b3f9fb8b9c4bddd8d7a",
            "7e91f60fb1c94ca2b661629b38ebbce2",
            "ebe8874127c6474d901a7ae1396a7468",
            "107a6f3afd6c4733937c5648b44e098b",
            "a9487cb255524bb5bf7923a236128320",
            "6db3980b85da4f81b0198cabd277dc6a"
          ]
        },
        "outputId": "4b846b12-464f-4530-93ce-b2ef1df80fdd"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single\n",
        "# linear classification layer on top.\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                                # You can increase this for multi-class tasks.\n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "417f42664d2849e689c02ca1543c51e6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=433, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e06f31d75f094d51beac92b3f6f14fd0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=440473133, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9PHFPduQyZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch)\n",
        "# I believe the 'W' stands for 'Weight Decay fix'\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5,    # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8    # args.adam_epsilon - default is 1e-8.\n",
        "                  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eA-yveMQySa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f597ae13-680f-4e75-fa67-5843223262f5"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "print(total_steps)\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7824\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSig-XMEQyG4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJkSyOibQx3M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "\n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcMNmfE5T8U-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b4f92e32-8703-4570-e0c2-1de1735be857"
      },
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch,\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # =======================================\n",
        "    #                               Training\n",
        "    # =======================================\n",
        "\n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i+1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0  = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to `train` just changes the *mode*,\n",
        "    # it doesn't *perform* the training. `dropout` and `batchnorm` layers behave differently during \n",
        "    # training vs. test \n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data,\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 100 batches.\n",
        "        if step % 100 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "\n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,} of {:5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader.\n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids\n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a backward pass.\n",
        "        # PyTorch doesn't do this automatically because accumulating the gradients is \n",
        "        # \"convenient while trainig RNNs\".\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Perform a forwad pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we have provided the `labels`.\n",
        "        # The documentation for this `model` function is here:\n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids,\n",
        "                        token_type_ids=None,\n",
        "                        attention_mask=b_input_mask,\n",
        "                        labels=b_labels)\n",
        "        \n",
        "        # The call to `model` always returns a tuple, so we need to pull the loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can calculate the average loss at the end.\n",
        "        # `loss` is a Tensor containing a single value; the `.item()` function just returns the Python value from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are modified\n",
        "        # based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "    # =======================================\n",
        "    #                               Validation\n",
        "    # ======================================= \n",
        "    # After the completion of each training epoch, measure our performance on our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy= 0,  0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0  \n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "\n",
        "        # Add  batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        # Telling the model not to compute or store gradients, saving memory and speeding up validataion\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which differentiates sentence 1 and 2 in 2-sentence task.\n",
        "            output = model(b_input_ids,\n",
        "                           token_type_ids=None,\n",
        "                           attention_mask=b_input_mask)\n",
        "            \n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output values prior to applying \n",
        "        # an activation function like the softmax.\n",
        "        logits = output[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "\n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "        \n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   100 of 1,956.    Elapsed: 0:01:14.\n",
            "  Batch   200 of 1,956.    Elapsed: 0:02:28.\n",
            "  Batch   300 of 1,956.    Elapsed: 0:03:43.\n",
            "  Batch   400 of 1,956.    Elapsed: 0:04:57.\n",
            "  Batch   500 of 1,956.    Elapsed: 0:06:12.\n",
            "  Batch   600 of 1,956.    Elapsed: 0:07:26.\n",
            "  Batch   700 of 1,956.    Elapsed: 0:08:40.\n",
            "  Batch   800 of 1,956.    Elapsed: 0:09:55.\n",
            "  Batch   900 of 1,956.    Elapsed: 0:11:09.\n",
            "  Batch 1,000 of 1,956.    Elapsed: 0:12:24.\n",
            "  Batch 1,100 of 1,956.    Elapsed: 0:13:38.\n",
            "  Batch 1,200 of 1,956.    Elapsed: 0:14:53.\n",
            "  Batch 1,300 of 1,956.    Elapsed: 0:16:07.\n",
            "  Batch 1,400 of 1,956.    Elapsed: 0:17:22.\n",
            "  Batch 1,500 of 1,956.    Elapsed: 0:18:36.\n",
            "  Batch 1,600 of 1,956.    Elapsed: 0:19:51.\n",
            "  Batch 1,700 of 1,956.    Elapsed: 0:21:06.\n",
            "  Batch 1,800 of 1,956.    Elapsed: 0:22:20.\n",
            "  Batch 1,900 of 1,956.    Elapsed: 0:23:35.\n",
            "\n",
            "  Average training loss: 0.14\n",
            "  Training epoch took: 0:24:16\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "  Validation took: 0:00:52\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch   100 of 1,956.    Elapsed: 0:01:15.\n",
            "  Batch   200 of 1,956.    Elapsed: 0:02:29.\n",
            "  Batch   300 of 1,956.    Elapsed: 0:03:44.\n",
            "  Batch   400 of 1,956.    Elapsed: 0:04:58.\n",
            "  Batch   500 of 1,956.    Elapsed: 0:06:13.\n",
            "  Batch   600 of 1,956.    Elapsed: 0:07:28.\n",
            "  Batch   700 of 1,956.    Elapsed: 0:08:43.\n",
            "  Batch   800 of 1,956.    Elapsed: 0:09:58.\n",
            "  Batch   900 of 1,956.    Elapsed: 0:11:12.\n",
            "  Batch 1,000 of 1,956.    Elapsed: 0:12:27.\n",
            "  Batch 1,100 of 1,956.    Elapsed: 0:13:41.\n",
            "  Batch 1,200 of 1,956.    Elapsed: 0:14:56.\n",
            "  Batch 1,300 of 1,956.    Elapsed: 0:16:11.\n",
            "  Batch 1,400 of 1,956.    Elapsed: 0:17:26.\n",
            "  Batch 1,500 of 1,956.    Elapsed: 0:18:40.\n",
            "  Batch 1,600 of 1,956.    Elapsed: 0:19:55.\n",
            "  Batch 1,700 of 1,956.    Elapsed: 0:21:10.\n",
            "  Batch 1,800 of 1,956.    Elapsed: 0:22:24.\n",
            "  Batch 1,900 of 1,956.    Elapsed: 0:23:39.\n",
            "\n",
            "  Average training loss: 0.09\n",
            "  Training epoch took: 0:24:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "  Validation took: 0:00:52\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch   100 of 1,956.    Elapsed: 0:01:15.\n",
            "  Batch   200 of 1,956.    Elapsed: 0:02:29.\n",
            "  Batch   300 of 1,956.    Elapsed: 0:03:44.\n",
            "  Batch   400 of 1,956.    Elapsed: 0:04:58.\n",
            "  Batch   500 of 1,956.    Elapsed: 0:06:13.\n",
            "  Batch   600 of 1,956.    Elapsed: 0:07:27.\n",
            "  Batch   700 of 1,956.    Elapsed: 0:08:42.\n",
            "  Batch   800 of 1,956.    Elapsed: 0:09:56.\n",
            "  Batch   900 of 1,956.    Elapsed: 0:11:11.\n",
            "  Batch 1,000 of 1,956.    Elapsed: 0:12:25.\n",
            "  Batch 1,100 of 1,956.    Elapsed: 0:13:40.\n",
            "  Batch 1,200 of 1,956.    Elapsed: 0:14:54.\n",
            "  Batch 1,300 of 1,956.    Elapsed: 0:16:09.\n",
            "  Batch 1,400 of 1,956.    Elapsed: 0:17:24.\n",
            "  Batch 1,500 of 1,956.    Elapsed: 0:18:38.\n",
            "  Batch 1,600 of 1,956.    Elapsed: 0:19:53.\n",
            "  Batch 1,700 of 1,956.    Elapsed: 0:21:07.\n",
            "  Batch 1,800 of 1,956.    Elapsed: 0:22:22.\n",
            "  Batch 1,900 of 1,956.    Elapsed: 0:23:36.\n",
            "\n",
            "  Average training loss: 0.05\n",
            "  Training epoch took: 0:24:18\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "  Validation took: 0:00:52\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch   100 of 1,956.    Elapsed: 0:01:14.\n",
            "  Batch   200 of 1,956.    Elapsed: 0:02:29.\n",
            "  Batch   300 of 1,956.    Elapsed: 0:03:44.\n",
            "  Batch   400 of 1,956.    Elapsed: 0:04:58.\n",
            "  Batch   500 of 1,956.    Elapsed: 0:06:12.\n",
            "  Batch   600 of 1,956.    Elapsed: 0:07:27.\n",
            "  Batch   700 of 1,956.    Elapsed: 0:08:41.\n",
            "  Batch   800 of 1,956.    Elapsed: 0:09:56.\n",
            "  Batch   900 of 1,956.    Elapsed: 0:11:10.\n",
            "  Batch 1,000 of 1,956.    Elapsed: 0:12:25.\n",
            "  Batch 1,100 of 1,956.    Elapsed: 0:13:39.\n",
            "  Batch 1,200 of 1,956.    Elapsed: 0:14:54.\n",
            "  Batch 1,300 of 1,956.    Elapsed: 0:16:09.\n",
            "  Batch 1,400 of 1,956.    Elapsed: 0:17:23.\n",
            "  Batch 1,500 of 1,956.    Elapsed: 0:18:38.\n",
            "  Batch 1,600 of 1,956.    Elapsed: 0:19:52.\n",
            "  Batch 1,700 of 1,956.    Elapsed: 0:21:07.\n",
            "  Batch 1,800 of 1,956.    Elapsed: 0:22:21.\n",
            "  Batch 1,900 of 1,956.    Elapsed: 0:23:35.\n",
            "\n",
            "  Average training loss: 0.03\n",
            "  Training epoch took: 0:24:17\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "  Validation took: 0:00:52\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoglqjP0wI5W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "868b6648-64d5-47a9-a22e-824ae33cf816"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcCjkucgQSYx",
        "colab_type": "text"
      },
      "source": [
        "## Performance On Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrMvgRqlwAG3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "c01165b6-9cf4-4531-b831-c553fae99bca"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to their word IDs.\n",
        "test_input_ids = []\n",
        "\n",
        "# For every sentence,\n",
        "for sen in test_comments.comment:\n",
        "\n",
        "    # Report progress.\n",
        "    if ((len(input_ids) % 20000) == 0):\n",
        "        print('  Read {:,} comments.'.format(len(input_ids)))\n",
        "\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "        sen,                                        # Sentence to encode.\n",
        "        add_special_tokens = True,      # Add '[CLS]' and '[SEP]'\n",
        "        max_length = MAX_LEN,           # Truncate all sentences.\n",
        "    )\n",
        "\n",
        "    # Add the encoded sentence to the list.\n",
        "    test_input_ids.append(encoded_sent)\n",
        "\n",
        "print('DONE.')\n",
        "print('')\n",
        "print('{:>10,} test comments'.format(len(test_input_ids)))\n",
        "\n",
        "# Also retrieve the labels as a list.\n",
        "\n",
        "# Get the labels from the DataFrame, and convert from booleans to ints.\n",
        "test_labels = test_comments.attack.to_numpy().astype(int)\n",
        "\n",
        "print('{:>10,} positive (contains attack)'.format(np.sum(test_labels)))\n",
        "print('{:>10,} negative (not an attack)'.format(len(test_labels) - np.sum(test_labels)))\n",
        "\n",
        "# Pad our input tokens\n",
        "test_input_ids = pad_sequences(test_input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                               truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Create attention masks\n",
        "test_attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in test_input_ids:\n",
        "    seq_mask = [float(i>0) for i in seq]\n",
        "    test_attention_masks.append(seq_mask)\n",
        "\n",
        "# Convert to tensors.\n",
        "test_inputs = torch.tensor(test_input_ids)\n",
        "test_masks = torch.tensor(test_attention_masks)\n",
        "test_labels = torch.tensor(test_labels)\n",
        "\n",
        "# Set the batch size.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader.\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DONE.\n",
            "\n",
            "    23,178 test comments\n",
            "     2,756 positive (contains attack)\n",
            "    20,422 negative (not an attack)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPkXD-_ov_1z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "517b2299-6254-4815-90a7-b9352bc808a8"
      },
      "source": [
        "# Prediction on test set\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(test_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables\n",
        "predictions, true_labels = [], []\n",
        "\n",
        "# Measure elapsed time.\n",
        "t0 = time.time()\n",
        "\n",
        "# Predict\n",
        "for (step, batch) in enumerate(test_dataloader):\n",
        "\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "    # Progress update every 100 batches.\n",
        "    if step % 100 == 0 and not step == 0:\n",
        "        # Calculate elaped time in minutes.\n",
        "        elapsed = format_time(time.time() - t0)\n",
        "\n",
        "        # Report progress.\n",
        "        print('  Batch {:>5,} of {:5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n",
        "\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    # Telling the model not to compute or store gradients, saving memory and speeding up prediction\n",
        "    with torch.no_grad():\n",
        "        # Forward pass, calculate logit predictions\n",
        "        outputs = model(b_input_ids, token_type_ids=None, \n",
        "                        attention_mask=b_input_mask)\n",
        "        \n",
        "    logits = outputs[0]\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    # Store predictions and true labels\n",
        "    predictions.append(logits)\n",
        "    true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 23,178 test sentences...\n",
            "  Batch   100 of   725.    Elapsed: 0:00:24.\n",
            "  Batch   200 of   725.    Elapsed: 0:00:48.\n",
            "  Batch   300 of   725.    Elapsed: 0:01:12.\n",
            "  Batch   400 of   725.    Elapsed: 0:01:36.\n",
            "  Batch   500 of   725.    Elapsed: 0:02:00.\n",
            "  Batch   600 of   725.    Elapsed: 0:02:25.\n",
            "  Batch   700 of   725.    Elapsed: 0:02:49.\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZxUamTlv_Vz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d12aea21-a1ce-4540-c406-624de2eb2a24"
      },
      "source": [
        "predictions[0:10]"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[ 5.43135  , -4.0807185],\n",
              "        [ 4.597425 , -3.4614418],\n",
              "        [ 5.2029805, -3.8499084],\n",
              "        [ 5.43569  , -4.196341 ],\n",
              "        [ 5.240312 , -3.9164932],\n",
              "        [ 5.4701114, -4.1476755],\n",
              "        [ 5.4822345, -4.063522 ],\n",
              "        [ 4.17534  , -3.1728623],\n",
              "        [ 5.5162745, -4.17683  ],\n",
              "        [ 5.4228077, -3.9708762],\n",
              "        [ 5.3999577, -4.0484023],\n",
              "        [ 5.4844804, -4.143347 ],\n",
              "        [ 5.554893 , -4.2400174],\n",
              "        [ 5.3096027, -3.868986 ],\n",
              "        [ 5.4283338, -4.090388 ],\n",
              "        [ 5.326691 , -3.9882448],\n",
              "        [ 3.5734868, -2.635085 ],\n",
              "        [ 4.595947 , -3.5288842],\n",
              "        [ 5.4501967, -4.1388345],\n",
              "        [ 5.5220246, -4.186985 ],\n",
              "        [ 5.0823264, -3.7486613],\n",
              "        [ 5.5255437, -4.2840915],\n",
              "        [ 5.192801 , -3.9431345],\n",
              "        [ 5.3387275, -4.0219254],\n",
              "        [ 5.560451 , -4.240357 ],\n",
              "        [ 5.3670015, -3.9867408],\n",
              "        [ 5.392772 , -4.103932 ],\n",
              "        [ 4.2843475, -3.2214487],\n",
              "        [ 5.487993 , -4.157152 ],\n",
              "        [ 4.837236 , -3.5553339],\n",
              "        [ 4.913093 , -3.7768197],\n",
              "        [ 5.472227 , -4.2356243]], dtype=float32),\n",
              " array([[ 5.2538056, -3.8715463],\n",
              "        [ 5.2556586, -3.9228978],\n",
              "        [ 5.5078926, -4.181313 ],\n",
              "        [ 4.3217835, -3.0952156],\n",
              "        [ 4.9776473, -3.7838545],\n",
              "        [ 5.533898 , -4.2590494],\n",
              "        [ 5.1893706, -3.8123336],\n",
              "        [ 5.3296304, -4.048206 ],\n",
              "        [ 4.8392463, -3.3599744],\n",
              "        [ 5.514237 , -4.198028 ],\n",
              "        [ 4.203855 , -3.106302 ],\n",
              "        [ 4.9724193, -3.650119 ],\n",
              "        [ 5.333487 , -4.105561 ],\n",
              "        [ 5.376324 , -4.1128936],\n",
              "        [ 4.2694583, -3.1707146],\n",
              "        [ 4.951589 , -3.7181838],\n",
              "        [ 5.5396237, -4.2052727],\n",
              "        [ 5.4250503, -4.1939263],\n",
              "        [ 5.2637324, -3.8830388],\n",
              "        [ 5.3814473, -4.130902 ],\n",
              "        [ 5.134685 , -3.8901913],\n",
              "        [ 5.2697234, -3.994122 ],\n",
              "        [ 5.265741 , -4.0217566],\n",
              "        [ 5.476533 , -4.18317  ],\n",
              "        [ 5.381158 , -4.0330024],\n",
              "        [ 5.479093 , -4.175233 ],\n",
              "        [ 4.0906634, -3.0154393],\n",
              "        [ 5.488876 , -4.1607084],\n",
              "        [ 5.3916135, -4.0865245],\n",
              "        [ 5.3949404, -4.181269 ],\n",
              "        [ 5.4594636, -4.103906 ],\n",
              "        [ 5.0248437, -3.7683067]], dtype=float32),\n",
              " array([[ 5.300899 , -4.035556 ],\n",
              "        [ 5.395021 , -4.0742126],\n",
              "        [ 5.3767295, -4.0745296],\n",
              "        [ 5.385198 , -4.046394 ],\n",
              "        [ 5.3743854, -3.986636 ],\n",
              "        [ 5.457197 , -4.2560277],\n",
              "        [ 5.0604186, -3.7781377],\n",
              "        [ 5.556199 , -4.2197604],\n",
              "        [ 5.318427 , -4.0005083],\n",
              "        [ 5.48931  , -4.2283764],\n",
              "        [ 5.445115 , -4.110128 ],\n",
              "        [ 5.3118157, -4.0336213],\n",
              "        [ 5.491487 , -4.2422705],\n",
              "        [ 5.1997533, -3.8949559],\n",
              "        [ 5.5384912, -4.190333 ],\n",
              "        [ 5.135718 , -3.6955633],\n",
              "        [ 4.976919 , -3.6015885],\n",
              "        [ 5.4156137, -4.1589346],\n",
              "        [ 5.423242 , -4.173223 ],\n",
              "        [ 4.4196258, -3.3494275],\n",
              "        [ 5.3858056, -4.0824265],\n",
              "        [ 5.37742  , -4.122572 ],\n",
              "        [ 5.4962883, -4.251161 ],\n",
              "        [ 5.418966 , -4.063055 ],\n",
              "        [-1.286079 ,  0.7293226],\n",
              "        [ 5.402163 , -4.107389 ],\n",
              "        [ 5.3998604, -4.2119117],\n",
              "        [ 5.2807593, -4.0225797],\n",
              "        [ 5.343671 , -3.9670048],\n",
              "        [ 4.368339 , -3.1019998],\n",
              "        [ 5.2154574, -3.9437592],\n",
              "        [ 5.2475038, -3.8830495]], dtype=float32),\n",
              " array([[ 5.5114827, -4.2829566],\n",
              "        [ 5.5235353, -4.171074 ],\n",
              "        [ 5.4299884, -4.1302404],\n",
              "        [ 4.463454 , -3.1880848],\n",
              "        [ 4.927576 , -3.5457666],\n",
              "        [ 5.531424 , -4.2008467],\n",
              "        [-3.145138 ,  2.149257 ],\n",
              "        [ 5.206561 , -3.8794465],\n",
              "        [ 5.518431 , -4.1594043],\n",
              "        [ 5.051986 , -3.6589901],\n",
              "        [ 5.3859887, -4.131961 ],\n",
              "        [ 5.1433153, -3.8335874],\n",
              "        [ 5.528437 , -4.2033815],\n",
              "        [ 5.196643 , -3.8455179],\n",
              "        [ 5.255228 , -4.015091 ],\n",
              "        [ 5.225014 , -3.9305272],\n",
              "        [ 5.444698 , -4.1221886],\n",
              "        [ 5.462351 , -4.210379 ],\n",
              "        [ 5.4832816, -4.1626678],\n",
              "        [ 5.314896 , -4.0713444],\n",
              "        [ 5.3126583, -4.090319 ],\n",
              "        [ 5.496307 , -4.090698 ],\n",
              "        [ 5.446159 , -4.129005 ],\n",
              "        [ 5.4019475, -4.1180854],\n",
              "        [ 4.3167434, -3.1993456],\n",
              "        [ 4.9754267, -3.617138 ],\n",
              "        [ 5.3815904, -4.1416698],\n",
              "        [ 5.2965603, -3.963538 ],\n",
              "        [-1.2883178,  0.7328278],\n",
              "        [ 4.935533 , -3.6571178],\n",
              "        [ 3.400453 , -2.543452 ],\n",
              "        [ 5.4850397, -4.2034473]], dtype=float32),\n",
              " array([[ 5.426343 , -4.058358 ],\n",
              "        [ 5.355119 , -4.006176 ],\n",
              "        [ 5.196791 , -3.9755495],\n",
              "        [ 5.4531174, -4.104737 ],\n",
              "        [ 5.452077 , -4.188066 ],\n",
              "        [-2.5248263,  1.7298604],\n",
              "        [ 4.8599544, -3.6085203],\n",
              "        [ 2.5870051, -1.8053671],\n",
              "        [ 4.799905 , -3.7399406],\n",
              "        [ 5.384679 , -4.0612016],\n",
              "        [ 1.9848813, -1.4291253],\n",
              "        [ 4.8865104, -3.631117 ],\n",
              "        [ 5.042236 , -3.7061255],\n",
              "        [ 5.3766055, -4.1468015],\n",
              "        [ 5.253485 , -3.9272726],\n",
              "        [ 5.0634665, -3.8075929],\n",
              "        [ 2.4534297, -1.7532713],\n",
              "        [ 3.3397276, -2.3743272],\n",
              "        [ 5.2756653, -3.9090054],\n",
              "        [ 4.641894 , -3.5683382],\n",
              "        [-2.1660845,  1.4977252],\n",
              "        [ 5.541515 , -4.2125726],\n",
              "        [ 5.5152283, -4.2085767],\n",
              "        [ 5.467479 , -4.161997 ],\n",
              "        [ 5.410911 , -4.0653553],\n",
              "        [ 5.4061475, -4.0659604],\n",
              "        [ 4.4883223, -3.2679074],\n",
              "        [ 4.3587704, -3.3385775],\n",
              "        [ 5.5541663, -4.2766557],\n",
              "        [ 5.013972 , -3.7639925],\n",
              "        [ 5.2121844, -3.9890063],\n",
              "        [ 5.31105  , -3.9589643]], dtype=float32),\n",
              " array([[ 5.2220817 , -3.8852181 ],\n",
              "        [ 5.096519  , -3.8301609 ],\n",
              "        [ 4.5275893 , -3.3427517 ],\n",
              "        [-2.279029  ,  1.5349158 ],\n",
              "        [ 5.3037395 , -3.9923763 ],\n",
              "        [ 5.4391146 , -4.198975  ],\n",
              "        [ 4.831823  , -3.544483  ],\n",
              "        [ 3.2818186 , -2.356049  ],\n",
              "        [ 5.3940644 , -4.1183677 ],\n",
              "        [ 4.5440726 , -3.4263175 ],\n",
              "        [ 5.3488674 , -4.0014596 ],\n",
              "        [ 3.9753976 , -2.9137933 ],\n",
              "        [ 5.5004687 , -4.174517  ],\n",
              "        [ 5.2306914 , -3.887057  ],\n",
              "        [ 5.468411  , -4.1401105 ],\n",
              "        [ 1.8992587 , -1.1993924 ],\n",
              "        [ 5.298141  , -3.9230304 ],\n",
              "        [ 5.0579286 , -3.7088711 ],\n",
              "        [ 4.9830604 , -3.7070842 ],\n",
              "        [ 5.460772  , -4.1708426 ],\n",
              "        [ 5.2573924 , -3.8962035 ],\n",
              "        [ 5.4351697 , -4.162905  ],\n",
              "        [ 5.1305127 , -3.9049475 ],\n",
              "        [ 5.478809  , -4.141188  ],\n",
              "        [ 5.1301684 , -3.9068274 ],\n",
              "        [ 5.369158  , -4.0585637 ],\n",
              "        [ 4.89111   , -3.7031734 ],\n",
              "        [ 4.9608164 , -3.6122632 ],\n",
              "        [-0.28882384, -0.08296825],\n",
              "        [ 5.342772  , -4.118634  ],\n",
              "        [ 5.4631066 , -4.0267425 ],\n",
              "        [ 5.426874  , -4.127703  ]], dtype=float32),\n",
              " array([[ 5.4500875, -4.1427283],\n",
              "        [ 5.272012 , -3.922525 ],\n",
              "        [ 5.3324876, -4.0124974],\n",
              "        [ 5.241836 , -3.988877 ],\n",
              "        [ 5.430305 , -4.1839437],\n",
              "        [ 5.314261 , -4.0438604],\n",
              "        [ 2.7459657, -2.062171 ],\n",
              "        [ 4.590529 , -3.3443534],\n",
              "        [ 4.1439905, -3.046077 ],\n",
              "        [ 4.952759 , -3.6524353],\n",
              "        [ 3.406953 , -2.374637 ],\n",
              "        [ 2.3458736, -1.8320854],\n",
              "        [ 5.1831036, -3.7904568],\n",
              "        [ 4.8084626, -3.5252323],\n",
              "        [ 3.6671154, -2.6256115],\n",
              "        [ 4.947343 , -3.5901263],\n",
              "        [ 5.410084 , -4.152666 ],\n",
              "        [ 5.566479 , -4.1783257],\n",
              "        [ 5.5365787, -4.2330713],\n",
              "        [ 4.4909205, -3.4299731],\n",
              "        [ 5.1837406, -3.8058364],\n",
              "        [ 5.493726 , -4.1462436],\n",
              "        [ 5.516855 , -4.2894855],\n",
              "        [ 5.461716 , -4.144648 ],\n",
              "        [ 4.2099686, -3.1970298],\n",
              "        [ 5.4657083, -4.0766892],\n",
              "        [ 3.5141003, -2.6443436],\n",
              "        [ 4.574696 , -3.411751 ],\n",
              "        [ 4.479477 , -3.4387724],\n",
              "        [ 4.129355 , -2.9603298],\n",
              "        [ 5.4946685, -4.226595 ],\n",
              "        [ 4.7603784, -3.5759366]], dtype=float32),\n",
              " array([[ 5.22998  , -3.8989506],\n",
              "        [ 4.62727  , -3.5161207],\n",
              "        [ 5.2467384, -4.003106 ],\n",
              "        [ 5.0838833, -3.7301426],\n",
              "        [ 4.624779 , -3.3708727],\n",
              "        [ 5.501288 , -4.1779866],\n",
              "        [ 5.5021577, -4.1358433],\n",
              "        [ 5.387923 , -4.0268197],\n",
              "        [ 5.39391  , -4.0430226],\n",
              "        [ 5.3329606, -3.9436512],\n",
              "        [ 5.457484 , -4.2270913],\n",
              "        [ 4.831526 , -3.6528254],\n",
              "        [ 5.461303 , -4.117969 ],\n",
              "        [ 5.2780957, -3.8968644],\n",
              "        [ 5.278866 , -3.9510126],\n",
              "        [ 5.355661 , -4.1682024],\n",
              "        [ 5.074125 , -3.7028506],\n",
              "        [ 5.5256524, -4.2130594],\n",
              "        [ 5.387303 , -4.0357842],\n",
              "        [ 5.1998754, -3.8378658],\n",
              "        [-2.5835028,  1.7536069],\n",
              "        [ 4.712457 , -3.3902724],\n",
              "        [ 5.494749 , -4.2219605],\n",
              "        [ 5.377855 , -4.1340117],\n",
              "        [ 5.161177 , -3.9164536],\n",
              "        [-1.891978 ,  1.3880231],\n",
              "        [ 5.07652  , -3.8013415],\n",
              "        [-1.4576713,  1.0712835],\n",
              "        [ 4.5357213, -3.4483316],\n",
              "        [ 5.187512 , -3.9807591],\n",
              "        [ 5.488303 , -4.174469 ],\n",
              "        [ 5.2502856, -4.036819 ]], dtype=float32),\n",
              " array([[ 4.5356584, -3.3985226],\n",
              "        [ 5.393577 , -4.086617 ],\n",
              "        [ 5.463293 , -4.21639  ],\n",
              "        [ 5.54695  , -4.2858906],\n",
              "        [ 5.2682576, -3.9987485],\n",
              "        [-2.6624324,  1.8077208],\n",
              "        [ 4.798633 , -3.6184127],\n",
              "        [ 5.3184495, -3.9698799],\n",
              "        [ 4.5881543, -3.383561 ],\n",
              "        [ 5.447883 , -4.1521564],\n",
              "        [ 5.4165   , -4.1261272],\n",
              "        [ 4.494101 , -3.3133528],\n",
              "        [ 4.767463 , -3.6006236],\n",
              "        [ 5.354958 , -4.050154 ],\n",
              "        [ 5.448631 , -4.181068 ],\n",
              "        [ 5.4187636, -4.1287675],\n",
              "        [ 5.3159976, -4.013481 ],\n",
              "        [ 5.3802915, -4.1061697],\n",
              "        [ 5.3652625, -4.086414 ],\n",
              "        [ 2.7618191, -1.9567709],\n",
              "        [ 4.444735 , -3.213555 ],\n",
              "        [ 4.760546 , -3.4369195],\n",
              "        [ 5.239843 , -3.980441 ],\n",
              "        [ 5.330209 , -4.011886 ],\n",
              "        [ 5.1778207, -3.8983636],\n",
              "        [ 5.491265 , -4.1538916],\n",
              "        [ 5.5505404, -4.201356 ],\n",
              "        [ 4.3914275, -3.1794152],\n",
              "        [-2.728721 ,  1.8481518],\n",
              "        [ 5.0268064, -3.768466 ],\n",
              "        [ 5.385312 , -4.012403 ],\n",
              "        [ 5.441138 , -4.173414 ]], dtype=float32),\n",
              " array([[ 5.4384995, -4.2335277],\n",
              "        [ 4.8552275, -3.586826 ],\n",
              "        [ 5.4932003, -4.276974 ],\n",
              "        [ 5.3816824, -4.030221 ],\n",
              "        [ 5.156941 , -3.686106 ],\n",
              "        [ 4.438695 , -3.3080924],\n",
              "        [ 5.051719 , -3.8141997],\n",
              "        [ 5.375688 , -4.0709853],\n",
              "        [ 5.471972 , -4.204346 ],\n",
              "        [ 5.236156 , -3.9004257],\n",
              "        [ 3.6281152, -2.6599073],\n",
              "        [ 5.177928 , -3.9476264],\n",
              "        [ 3.9968965, -2.8652222],\n",
              "        [-2.2053506,  1.5181979],\n",
              "        [ 5.5276327, -4.201619 ],\n",
              "        [ 5.332174 , -4.1147814],\n",
              "        [ 5.5003433, -4.2656736],\n",
              "        [ 5.313503 , -3.9444892],\n",
              "        [ 5.4858646, -4.1904445],\n",
              "        [ 5.2496657, -3.8906143],\n",
              "        [-3.4954479,  2.3633578],\n",
              "        [ 5.428599 , -4.1713705],\n",
              "        [ 5.304045 , -4.048304 ],\n",
              "        [ 5.229869 , -3.9223626],\n",
              "        [ 5.343846 , -4.0001264],\n",
              "        [ 4.7234535, -3.4158018],\n",
              "        [ 5.5213265, -4.198597 ],\n",
              "        [ 5.3841186, -4.0770264],\n",
              "        [ 5.333826 , -4.0571227],\n",
              "        [ 5.4549546, -4.1659894],\n",
              "        [ 5.388159 , -4.064118 ],\n",
              "        [ 4.6759048, -3.497959 ]], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUCbfFZBlSb2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Combine the results across the batches.\n",
        "predictions = np.concatenate(predictions, axis=0)\n",
        "true_labels = np.concatenate(true_labels, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SvWr-Qslfo7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "c0f1986c-563c-47ac-975a-36550cef7453"
      },
      "source": [
        "predictions[0:10]"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 5.43135  , -4.0807185],\n",
              "       [ 4.597425 , -3.4614418],\n",
              "       [ 5.2029805, -3.8499084],\n",
              "       [ 5.43569  , -4.196341 ],\n",
              "       [ 5.240312 , -3.9164932],\n",
              "       [ 5.4701114, -4.1476755],\n",
              "       [ 5.4822345, -4.063522 ],\n",
              "       [ 4.17534  , -3.1728623],\n",
              "       [ 5.5162745, -4.17683  ],\n",
              "       [ 5.4228077, -3.9708762]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AR3eaualSFa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "102dfec0-4767-457b-f28a-11cfe25531a7"
      },
      "source": [
        "true_labels[0:10]"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WVNiuGvlrpx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "437cc27a-ec66-4cab-f621-1285534609ec"
      },
      "source": [
        "# Our performance metric for the test set.\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Use the model output for label 1 as our predictions.\n",
        "p1 = predictions[:,1]\n",
        "\n",
        "# Calculate the ROC AUC.\n",
        "auc = roc_auc_score(true_labels, p1)\n",
        "\n",
        "print('Test ROC AUC: %.3f' %auc)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test ROC AUC: 0.973\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEV5rY2JQSG8",
        "colab_type": "text"
      },
      "source": [
        "## Save Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "up-YD55vwBPA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "6f60c9a4-7d7b-4679-dd04-22bd922e9c0f"
      },
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults name for the model, you can reload it using from_pretrained()\n",
        "output_dir = './model_save/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to ./model_save/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./model_save/vocab.txt',\n",
              " './model_save/special_tokens_map.json',\n",
              " './model_save/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yANNRzbbwA5f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "f7923319-239a-40e0-e6ff-547d1aa82fcd"
      },
      "source": [
        "# Mount Google Drive to this Notebook instance.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6QNTMCBwAsC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gdrive_path = './drive/My Drive/BERT Document Classification Tutorial/model_save/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(gdrive_path):\n",
        "    os.makedirs(gdrive_path)\n",
        "\n",
        "# Copy the model files to a directory in your Google Drive.\n",
        "!cp -r ./model_save/ \"./drive/My Drive/BERT Document Classification Tutorial/model_save/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqVRl8_CFrAr",
        "colab_type": "text"
      },
      "source": [
        "# Part III - Semantic Similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSWYIkcsX3PS",
        "colab_type": "text"
      },
      "source": [
        "## Vectorize Comments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQoQ9Yh-YBLx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.output_hidden_states = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6643y_GeK_t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "58952405-3849-4fc7-fcd8-11bad1b28595"
      },
      "source": [
        "# Mount Google Drive to this Notebook instance.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61-rcxgOeWOl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copy the model files back from Google Drive to the Colab instance. \n",
        "!cp -r \"./drive/My Drive/BERT Document Classification Tutorial/model_save/\" ./model_save/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2nScvUdeV5v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d96f8a42-d86a-492c-8bf9-994770f98ceb"
      },
      "source": [
        "from transformers import BertForSequenceClassification, BertTokenizer\n",
        "\n",
        "# The name of the folder containing the model files.\n",
        "output_dir = './model_save/'\n",
        "\n",
        "# Load our fine-tuned model, and configure it to return the \"hidden states\", \n",
        "# from which we will be taking our text embeddings.\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    output_dir,\n",
        "    output_hidden_states = True, # Whether the model returns all hidden-states.\n",
        ") \n",
        "\n",
        "# Load the tokenizer.\n",
        "tokenizer = BertTokenizer.from_pretrained(output_dir)\n",
        "\n",
        "# Copy the model to the GPU.\n",
        "model.to(device)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSZ9oo1oeVnn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def text_to_embedding(tokenizer, model, in_text):\n",
        "    '''\n",
        "    Uses the provided BERT `model` and `tokenizer` to generate a vector representation of the input string, `in_text`.\n",
        "    Returns the vector stored as a numpy ndarray.\n",
        "    '''\n",
        "\n",
        "    # ===========================\n",
        "    #         STEP 1: Tokenization\n",
        "    # ===========================\n",
        "\n",
        "    MAX_LEN = 128\n",
        "\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Truncate the sentence to MAX_LEN if necessary.\n",
        "    #   (3) Prepend the `[CLS]` token to the start.\n",
        "    #   (4) Append the `[SEP]` token to the end. (After truncating!)\n",
        "    #   (5) Map tokens to their IDs.\n",
        "    input_ids = tokenizer.encode(\n",
        "        in_text,                                    # Sentence to encode.\n",
        "        add_special_tokens = True,      # Add '[CLS]' and '[SEP]'\n",
        "        max_length = MAX_LEN,           # Truncate all sentences.\n",
        "    )\n",
        "\n",
        "    # Pad our input tokens. Truncation was handled above by the `encode` function,\n",
        "    # which also makes sure that the `[SEP]` token is placed at the end *after* truncating.\n",
        "    # Note: `pad_sequences` expects a list of lists, but we only have one piece of text, \n",
        "    # so we surround `input_ids` with an extra set of brackets.\n",
        "    results = pad_sequences([input_ids], maxlen=MAX_LEN, dtype=\"long\",\n",
        "                                truncating=\"post\", padding=\"post\")\n",
        "\n",
        "    # Remove the outer list.\n",
        "    input_ids = results[0]\n",
        "\n",
        "    # Create attention masks\n",
        "    attn_mask = [int(i>0) for i in input_ids]\n",
        "\n",
        "    # Cast to tensors.\n",
        "    input_ids = torch.tensor(input_ids)\n",
        "    attn_mask = torch.tensor(attn_mask)\n",
        "\n",
        "    # Add an extra dimension for the \"batch\" (even though there is only one input in this batch.)\n",
        "    input_ids = input_ids.unsqueeze(0)\n",
        "    attn_mask = attn_mask.unsqueeze(0)\n",
        "\n",
        "    # ===========================\n",
        "    #         STEP 2: BERT Model\n",
        "    # ===========================\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Copy the inputs to the GPU\n",
        "    # Note -- I got stuck here for a while because I didn't assign the result back to the variable! Geez!\n",
        "    input_ids = input_ids.to(device)\n",
        "    attn_mask = attn_mask.to(device)\n",
        "\n",
        "    # Telling the model not to build the backwards graph will make this a little quicker.\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # Forward pass, return hidden states and predictions.\n",
        "        # This will return the logits rather than the loss because we have not provided labels.\n",
        "        logits, encoded_layers = model(\n",
        "            input_ids = input_ids,\n",
        "            token_type_ids = None,\n",
        "            attention_mask = attn_mask\n",
        "        )\n",
        "\n",
        "    # Retrieve our sentence embedding--take the `[CLS]` embedding from the final layer.\n",
        "    layer_i = 12 # The last BERT layer before the classifier.\n",
        "    batch_i = 0 # Only one input in the batch.\n",
        "    token_i = 0 # The first token, corresponding to [CLS]\n",
        "\n",
        "    # Grab the embedding.\n",
        "    vec = encoded_layers[layer_i][batch_i][token_i]\n",
        "\n",
        "    # Move to the CPU and convert to numpy ndarray.\n",
        "    vec = vec.detach().cpu().numpy()\n",
        "\n",
        "    return vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QV17V28Jv6rG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "1c40f158-af12-400e-916e-067a4111e6c3"
      },
      "source": [
        "# Get the text from one of the comments.\n",
        "input_text = comments.iloc[10].comment\n",
        "\n",
        "# Use `textwrap` to print the sentence nicely.\n",
        "wrapper = textwrap.TextWrapper(initial_indent=\"    \", subsequent_indent=\"    \", width = 80)\n",
        "\n",
        "print('Getting embedding for sentence:\\n\\n', wrapper.fill(input_text))\n",
        "\n",
        "# Use the BERT model and tokenizer to generate an embedding for `input_text`.\n",
        "vec = text_to_embedding(tokenizer, model, input_text)\n",
        "\n",
        "print('\\nDone. Embedding shape:', str(vec.shape))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Getting embedding for sentence:\n",
            "\n",
            "       :Correct. Full biographical details will put down his birth details, etc.\n",
            "    It is just a marker to me at the moment to detail the WR aspect. He\n",
            "    certainly wasn't Belarus; as a geo-political entity it had no real existence\n",
            "    at the time. I have put a tbc marker on this article for now.\n",
            "\n",
            "Done. Embedding shape: (768,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFJClindv6bB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "\n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6v30a37Yv6JV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5e3c60bd-0183-474c-d13f-c058f6f294b1"
      },
      "source": [
        "import time\n",
        "\n",
        "# Track the time.\n",
        "t0 = time.time()\n",
        "\n",
        "# Store the set of embeddings.\n",
        "embeddings = []\n",
        "\n",
        "num_comments = len(comments)\n",
        "\n",
        "print('Generating sentence embeddings for all {:,} comments...'.format(num_comments))\n",
        "\n",
        "row_num = 0\n",
        "\n",
        "# For each row of the dataframe,\n",
        "for index, row in comments.iterrows():\n",
        "\n",
        "    # Progress update every 2,000 comments.\n",
        "    if row_num % 2000 == 0 and not row_num == 0:\n",
        "\n",
        "        # Calculate elapsed time and format it.\n",
        "        elapsed = format_time(time.time()-t0)\n",
        "\n",
        "        # Calculate the time remaining based on our progress.\n",
        "        rows_per_sec = (time.time() - t0) / row_num\n",
        "        remaining_sec = rows_per_sec * (num_comments - row_num)\n",
        "        remaining = format_time(remaining_sec)\n",
        "\n",
        "        # Report progress.\n",
        "        print('  Comment {:>7,} of {:>7,}.    Elapsed: {:}. Remaining: {:}'.format(row_num, num_comments, elapsed, remaining))\n",
        "\n",
        "    # Vectorize this comment.\n",
        "    vec = text_to_embedding(tokenizer, model, row.comment)\n",
        "\n",
        "    # Store the embeddings.\n",
        "    embeddings.append(vec)\n",
        "\n",
        "    row_num += 1"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating sentence embeddings for all 115,864 comments...\n",
            "  Comment   2,000 of 115,864.    Elapsed: 0:00:31. Remaining: 0:29:42\n",
            "  Comment   4,000 of 115,864.    Elapsed: 0:01:03. Remaining: 0:29:22\n",
            "  Comment   6,000 of 115,864.    Elapsed: 0:01:34. Remaining: 0:28:47\n",
            "  Comment   8,000 of 115,864.    Elapsed: 0:02:06. Remaining: 0:28:12\n",
            "  Comment  10,000 of 115,864.    Elapsed: 0:02:36. Remaining: 0:27:32\n",
            "  Comment  12,000 of 115,864.    Elapsed: 0:03:07. Remaining: 0:26:58\n",
            "  Comment  14,000 of 115,864.    Elapsed: 0:03:38. Remaining: 0:26:26\n",
            "  Comment  16,000 of 115,864.    Elapsed: 0:04:09. Remaining: 0:25:52\n",
            "  Comment  18,000 of 115,864.    Elapsed: 0:04:40. Remaining: 0:25:22\n",
            "  Comment  20,000 of 115,864.    Elapsed: 0:05:11. Remaining: 0:24:49\n",
            "  Comment  22,000 of 115,864.    Elapsed: 0:05:41. Remaining: 0:24:17\n",
            "  Comment  24,000 of 115,864.    Elapsed: 0:06:12. Remaining: 0:23:45\n",
            "  Comment  26,000 of 115,864.    Elapsed: 0:06:43. Remaining: 0:23:13\n",
            "  Comment  28,000 of 115,864.    Elapsed: 0:07:14. Remaining: 0:22:42\n",
            "  Comment  30,000 of 115,864.    Elapsed: 0:07:44. Remaining: 0:22:09\n",
            "  Comment  32,000 of 115,864.    Elapsed: 0:08:15. Remaining: 0:21:38\n",
            "  Comment  34,000 of 115,864.    Elapsed: 0:08:46. Remaining: 0:21:07\n",
            "  Comment  36,000 of 115,864.    Elapsed: 0:09:17. Remaining: 0:20:36\n",
            "  Comment  38,000 of 115,864.    Elapsed: 0:09:49. Remaining: 0:20:06\n",
            "  Comment  40,000 of 115,864.    Elapsed: 0:10:19. Remaining: 0:19:35\n",
            "  Comment  42,000 of 115,864.    Elapsed: 0:10:50. Remaining: 0:19:03\n",
            "  Comment  44,000 of 115,864.    Elapsed: 0:11:20. Remaining: 0:18:31\n",
            "  Comment  46,000 of 115,864.    Elapsed: 0:11:51. Remaining: 0:18:00\n",
            "  Comment  48,000 of 115,864.    Elapsed: 0:12:22. Remaining: 0:17:29\n",
            "  Comment  50,000 of 115,864.    Elapsed: 0:12:53. Remaining: 0:16:58\n",
            "  Comment  52,000 of 115,864.    Elapsed: 0:13:24. Remaining: 0:16:27\n",
            "  Comment  54,000 of 115,864.    Elapsed: 0:13:55. Remaining: 0:15:56\n",
            "  Comment  56,000 of 115,864.    Elapsed: 0:14:26. Remaining: 0:15:25\n",
            "  Comment  58,000 of 115,864.    Elapsed: 0:14:56. Remaining: 0:14:54\n",
            "  Comment  60,000 of 115,864.    Elapsed: 0:15:27. Remaining: 0:14:23\n",
            "  Comment  62,000 of 115,864.    Elapsed: 0:15:58. Remaining: 0:13:52\n",
            "  Comment  64,000 of 115,864.    Elapsed: 0:16:28. Remaining: 0:13:21\n",
            "  Comment  66,000 of 115,864.    Elapsed: 0:16:59. Remaining: 0:12:50\n",
            "  Comment  68,000 of 115,864.    Elapsed: 0:17:29. Remaining: 0:12:19\n",
            "  Comment  70,000 of 115,864.    Elapsed: 0:18:00. Remaining: 0:11:48\n",
            "  Comment  72,000 of 115,864.    Elapsed: 0:18:31. Remaining: 0:11:17\n",
            "  Comment  74,000 of 115,864.    Elapsed: 0:19:01. Remaining: 0:10:46\n",
            "  Comment  76,000 of 115,864.    Elapsed: 0:19:32. Remaining: 0:10:15\n",
            "  Comment  78,000 of 115,864.    Elapsed: 0:20:03. Remaining: 0:09:44\n",
            "  Comment  80,000 of 115,864.    Elapsed: 0:20:33. Remaining: 0:09:13\n",
            "  Comment  82,000 of 115,864.    Elapsed: 0:21:04. Remaining: 0:08:42\n",
            "  Comment  84,000 of 115,864.    Elapsed: 0:21:35. Remaining: 0:08:11\n",
            "  Comment  86,000 of 115,864.    Elapsed: 0:22:05. Remaining: 0:07:40\n",
            "  Comment  88,000 of 115,864.    Elapsed: 0:22:36. Remaining: 0:07:09\n",
            "  Comment  90,000 of 115,864.    Elapsed: 0:23:07. Remaining: 0:06:39\n",
            "  Comment  92,000 of 115,864.    Elapsed: 0:23:37. Remaining: 0:06:08\n",
            "  Comment  94,000 of 115,864.    Elapsed: 0:24:08. Remaining: 0:05:37\n",
            "  Comment  96,000 of 115,864.    Elapsed: 0:24:39. Remaining: 0:05:06\n",
            "  Comment  98,000 of 115,864.    Elapsed: 0:25:10. Remaining: 0:04:35\n",
            "  Comment 100,000 of 115,864.    Elapsed: 0:25:41. Remaining: 0:04:04\n",
            "  Comment 102,000 of 115,864.    Elapsed: 0:26:11. Remaining: 0:03:34\n",
            "  Comment 104,000 of 115,864.    Elapsed: 0:26:42. Remaining: 0:03:03\n",
            "  Comment 106,000 of 115,864.    Elapsed: 0:27:13. Remaining: 0:02:32\n",
            "  Comment 108,000 of 115,864.    Elapsed: 0:27:44. Remaining: 0:02:01\n",
            "  Comment 110,000 of 115,864.    Elapsed: 0:28:15. Remaining: 0:01:30\n",
            "  Comment 112,000 of 115,864.    Elapsed: 0:28:45. Remaining: 0:01:00\n",
            "  Comment 114,000 of 115,864.    Elapsed: 0:29:16. Remaining: 0:00:29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6hm_x6p1NWX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "62fbe845-a585-4c83-9dbd-fe6cac88f3be"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Convert the list of vectors into a 2D array.\n",
        "vecs = np.stack(embeddings)\n",
        "\n",
        "vecs.shape"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(115864, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQPc3jE21NDq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "outputId": "8f717660-fc77-40f1-fa6c-d3ce10012b89"
      },
      "source": [
        "import os\n",
        "\n",
        "output_dir = './model_save/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# Use numpy to write out the matrix of embeddings.\n",
        "print(\"Saving embeddings to: ./model_save/embeddings.npy\")\n",
        "np.save('./model_save/embeddings.npy', vecs)\n",
        "\n",
        "# Copy the embeddings to a directory in your Google Drive.\n",
        "!cp -r ./model_save/embeddings.npy \"./drive/My Drive/BERT Document Classification Tutorial/model_save/\""
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving embeddings to: ./model_save/embeddings.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aW0tJFyxX2xu",
        "colab_type": "text"
      },
      "source": [
        "## Semantic Similarity Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Fsn7Y-q1MtJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install faiss -q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2klQcT_FpUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install faiss-gpu -q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5IdslV9FRAW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "outputId": "40abbaeb-9d86-4aca-c6eb-bab78471fe17"
      },
      "source": [
        "import faiss\n",
        "\n",
        "# =====================================\n",
        "#            FAISS Setup\n",
        "# =====================================\n",
        "\n",
        "# Build a flat (CPU) index\n",
        "cpu_index = faiss.IndexFlatL2(vecs.shape[1])\n",
        "\n",
        "# Use 1 GPU.\n",
        "n_gpu = 1\n",
        "\n",
        "# Print the number of available GPU.\n",
        "print('Number of available GPUs: %d    Using: %d' % (faiss.get_num_gpus(), n_gpu))\n",
        "\n",
        "# If using multiple GPUs, enable sharding so that the dataset is devided across\n",
        "# the GPUs rather than replicated.\n",
        "co = faiss.GpuMultipleClonerOptions()\n",
        "co.shard = True\n",
        "\n",
        "# Make it into a gpu index\n",
        "gpu_index = faiss.index_cpu_to_all_gpus(cpu_index, co=co, ngpu=n_gpu)\n",
        "\n",
        "# Add vecs to our GPU index\n",
        "print('Adding dataset to index...')\n",
        "t0 = time.time()\n",
        "\n",
        "# gpu_index.add(vecs)\n",
        "gpu_index.add(vecs)\n",
        "\n",
        "elapsed = time.time() - t0\n",
        "print('Building index took %.2f seconds' % (elapsed))"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of available GPUs: 1    Using: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-d61aa5ee9ffb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Make it into a gpu index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mgpu_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfaiss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_cpu_to_all_gpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpu_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mco\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mco\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Add vecs to our GPU index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/faiss/__init__.py\u001b[0m in \u001b[0;36mindex_cpu_to_all_gpus\u001b[0;34m(index, co, ngpu)\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mindex_cpu_to_all_gpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mco\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m     \u001b[0mindex_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_cpu_to_gpus_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mco\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mco\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mngpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mindex_gpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/faiss/__init__.py\u001b[0m in \u001b[0;36mindex_cpu_to_gpus_list\u001b[0;34m(index, co, gpus, ngpu)\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0mgpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mStandardGpuResources\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgpus\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m     \u001b[0mindex_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_cpu_to_gpu_multiple_py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mco\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mindex_gpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/faiss/__init__.py\u001b[0m in \u001b[0;36mindex_cpu_to_gpu_multiple_py\u001b[0;34m(resources, index, co, gpus)\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0mvdev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush_back\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0mvres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush_back\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_cpu_to_gpu_multiple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvdev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mco\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m     \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreferenced_objects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresources\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/faiss/swigfaiss.py\u001b[0m in \u001b[0;36mindex_cpu_to_gpu_multiple\u001b[0;34m(resources, devices, index, options)\u001b[0m\n\u001b[1;32m   5054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5055\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mindex_cpu_to_gpu_multiple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresources\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5056\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_swigfaiss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_cpu_to_gpu_multiple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresources\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5058\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mswig_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error in void faiss::gpu::allocMemorySpaceV(faiss::gpu::MemorySpace, void**, size_t) at gpu/utils/MemorySpace.cpp:26: Error: 'err == cudaSuccess' failed: failed to cudaMalloc 1073741824 bytes (error 2 out of memory)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sV-B_Qoq4DJO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "14db4eac-efc5-40a6-b6a5-7c2de0239c5e"
      },
      "source": [
        "import faiss\n",
        "\n",
        "# =====================================\n",
        "#            FAISS Setup\n",
        "# =====================================\n",
        "\n",
        "# Build a flat (CPU) index\n",
        "cpu_index = faiss.IndexFlatL2(vecs.shape[1])\n",
        "\n",
        "# Use 1 GPU.\n",
        "n_gpu = 1\n",
        "\n",
        "# Print the number of available GPU.\n",
        "print('Number of available GPUs: %d    Using: %d' % (faiss.get_num_gpus(), n_gpu))\n",
        "\n",
        "# If using multiple GPUs, enable sharding so that the dataset is devided across\n",
        "# the GPUs rather than replicated.\n",
        "co = faiss.GpuMultipleClonerOptions()\n",
        "co.shard = True\n",
        "\n",
        "# Make it into a gpu index\n",
        "# gpu_index = faiss.index_cpu_to_all_gpus(cpu_index, co=co, ngpu=n_gpu)\n",
        "\n",
        "# Add vecs to our GPU index\n",
        "print('Adding dataset to index...')\n",
        "t0 = time.time()\n",
        "\n",
        "# gpu_index.add(vecs)\n",
        "cpu_index.add(vecs)\n",
        "\n",
        "elapsed = time.time() - t0\n",
        "print('Building index took %.2f seconds' % (elapsed))"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of available GPUs: 1    Using: 1\n",
            "Adding dataset to index...\n",
            "Building index took 0.24 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWWCmcEX4CmE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "outputId": "5c301e43-fd65-4577-8fa4-001b3ff9af86"
      },
      "source": [
        "# Coment number 4 is short and sweet.\n",
        "print('==== Input Comment ====')\n",
        "print('Comment #4:')\n",
        "print(wrapper.fill(comments.iloc[4].comment))\n",
        "\n",
        "# Let's find the 5 most similar comments.\n",
        "D, I = cpu_index.search(vecs[4].reshape(1, 768), k=5)\n",
        "\n",
        "print('')\n",
        "print('==== Top 5 Results ====')\n",
        "\n",
        "# For each result,\n",
        "for i in range(I.shape[1]):\n",
        "\n",
        "    # Look up the comment row number for this result.\n",
        "    result_i = I[0, i]\n",
        "\n",
        "    # Look up the text for this comment.\n",
        "    text = comments.iloc[result_i].comment\n",
        "\n",
        "    print('Comment #{:,}:'.format(result_i))\n",
        "    print('L2 Distance: %.2f' % D[0, i])\n",
        "    print(wrapper.fill('\"' + text + '\"'))\n",
        "    print('')"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==== Input Comment ====\n",
            "Comment #4:\n",
            "    This page will need disambiguation.\n",
            "\n",
            "==== Top 5 Results ====\n",
            "Comment #4:\n",
            "L2 Distance: 0.00\n",
            "    \"This page will need disambiguation. \"\n",
            "\n",
            "Comment #8,612:\n",
            "L2 Distance: 16.44\n",
            "    \"why can't i edit this page?\"\n",
            "\n",
            "Comment #39,578:\n",
            "L2 Distance: 16.64\n",
            "    \"  This page needs to be expand.   \"\n",
            "\n",
            "Comment #2,051:\n",
            "L2 Distance: 16.74\n",
            "    \" The article is somewhat confusing on this point - perhaps someone can\n",
            "    offer some clarification.\"\n",
            "\n",
            "Comment #59,036:\n",
            "L2 Distance: 17.31\n",
            "    \"  *As these issues remain uneddressed, this article has now been delisted.\n",
            "    \"\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmuatgWN4CZH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "74dda9c7-c409-42cd-82cf-c5480825644d"
      },
      "source": [
        "query_text = \"The meadning of this page needs to be clarified.\"\n",
        "\n",
        "# Vectorize a new piece of text.\n",
        "query_vec = text_to_embedding(tokenizer, model, query_text)\n",
        "\n",
        "# Let's find the 5 most similar comments.\n",
        "D, I = cpu_index.search(query_vec.reshape(1, 768), k=5)\n",
        "\n",
        "print('')\n",
        "print('==== Top 5 Results ====')\n",
        "\n",
        "# For each result,\n",
        "for i in range(I.shape[1]):\n",
        "\n",
        "    # Look up the comment row number for this result.\n",
        "    result_i = I[0, i]\n",
        "\n",
        "    # Look up the text for this comment.\n",
        "    text = comments.iloc[result_i].comment\n",
        "\n",
        "    print('Comment #{:,}:'.format(result_i))\n",
        "    print('L2Distance: %.2f' % D[0, i])\n",
        "    print(wrapper.fill('\"' +text + '\"'))\n",
        "    print('')"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "==== Top 5 Results ====\n",
            "Comment #39,578:\n",
            "L2Distance: 17.01\n",
            "    \"  This page needs to be expand.   \"\n",
            "\n",
            "Comment #88,451:\n",
            "L2Distance: 17.39\n",
            "    \"  I intend to expand the article so it will be more complete. [  ]\"\n",
            "\n",
            "Comment #78,013:\n",
            "L2Distance: 17.54\n",
            "    \"  == Full re-write ==  The article is in need of a full re-write; as\n",
            "    written, it contains large guide-oriented sections and otherwise lacks\n",
            "    encyclopedic character.   I will undertake rectifying these issues over the\n",
            "    next few days; developing or expanding the content will not be addressed by\n",
            "    me at this time.  \"\n",
            "\n",
            "Comment #3,035:\n",
            "L2Distance: 17.57\n",
            "    \"Perhaps this should be moved to the page devoted to the album.  \"\n",
            "\n",
            "Comment #82,620:\n",
            "L2Distance: 17.82\n",
            "    \"  ==Flags in table == This issue was addressed and resolved  here in 2008.\n",
            "    Consensus may change; but further discussion is needed before disturbing the\n",
            "    well-settled status quo.   \"\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELu5KN07EZ95",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "38417491-3876-47bb-da1e-5a0c25c0c83f"
      },
      "source": [
        "query_text = \"This article really needs more citations.\"\n",
        "\n",
        "# Vectorize a new piece of text.\n",
        "query_vec = text_to_embedding(tokenizer, model, query_text)\n",
        "\n",
        "# Let's find the 5 most similar comments.\n",
        "D, I = cpu_index.search(query_vec.reshape(1, 768), k=5)\n",
        "\n",
        "print('')\n",
        "print('==== Top 5 Results ====')\n",
        "\n",
        "# For each result,\n",
        "for i in range(I.shape[1]):\n",
        "\n",
        "    # Look up the comment row number for this result.\n",
        "    result_i = I[0, i]\n",
        "\n",
        "    # Look up the text for this comment.\n",
        "    text = comments.iloc[result_i].comment\n",
        "\n",
        "    print('Comment #{:,}:'.format(result_i))\n",
        "    print('L2Distance: %.2f' % D[0, i])\n",
        "    print(wrapper.fill('\"' +text + '\"'))\n",
        "    print('')"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "==== Top 5 Results ====\n",
            "Comment #77,417:\n",
            "L2Distance: 13.69\n",
            "    \"       A couple of these images should be added to the article.   \"\n",
            "\n",
            "Comment #2,051:\n",
            "L2Distance: 13.93\n",
            "    \" The article is somewhat confusing on this point - perhaps someone can\n",
            "    offer some clarification.\"\n",
            "\n",
            "Comment #32,761:\n",
            "L2Distance: 14.98\n",
            "    \" ::However, feel free to move that information deeper into the article.  \"\n",
            "\n",
            "Comment #59,036:\n",
            "L2Distance: 15.46\n",
            "    \"  *As these issues remain uneddressed, this article has now been delisted.\n",
            "    \"\n",
            "\n",
            "Comment #66,209:\n",
            "L2Distance: 15.95\n",
            "    \"  ===Lead=== I'll leave this until last, as it may need to reflect changes\n",
            "    in the rest of the article.\"\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Wwk2YDYE-Cb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}